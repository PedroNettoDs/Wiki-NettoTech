<!DOCTYPE html> <html lang="pt-br"><head>
<title>deep-research-report</title>
<base href="../..">
<meta name="pathname" content="projeto/llm-alfred/deep-research-report.html">
<meta name="description" content="Obsidian - MrNotte - deep-research-report">
<meta property="og:title" content="deep-research-report">
<meta property="og:description" content="Obsidian - MrNotte - deep-research-report">
<meta property="og:type" content="website">
<meta property="og:url" content="projeto/llm-alfred/deep-research-report.html">
<meta property="og:image" content="undefined">
<meta charset="UTF-8"><meta property="og:site_name" content="Obsidian - MrNotte"><meta name="viewport" content="width=device-width, initial-scale=1.0, user-scalable=yes, minimum-scale=1.0, maximum-scale=5.0"><link rel="alternate" type="application/rss+xml" title="RSS Feed" href="site-lib/rss.xml"><script async="" id="webpage-script" src="site-lib/scripts/webpage.js" onload="this.onload=null;this.setAttribute(&quot;loaded&quot;, &quot;true&quot;)"></script><script async="" id="graph-wasm-script" src="site-lib/scripts/graph-wasm.js" onload="this.onload=null;this.setAttribute(&quot;loaded&quot;, &quot;true&quot;)"></script><script async="" id="graph-render-worker-script" src="site-lib/scripts/graph-render-worker.js" onload="this.onload=null;this.setAttribute(&quot;loaded&quot;, &quot;true&quot;)"></script><link rel="icon" href="site-lib/media/favicon.png"><link rel="stylesheet" href="site-lib/styles/obsidian.css"><link rel="stylesheet" href="site-lib/styles/theme.css"><link rel="preload" href="site-lib/styles/global-variable-styles.css" as="style" onload="this.onload=null;this.rel='stylesheet'"><noscript><link rel="stylesheet" href="site-lib/styles/global-variable-styles.css"></noscript><link rel="preload" href="site-lib/styles/supported-plugins.css" as="style" onload="this.onload=null;this.rel='stylesheet'"><noscript><link rel="stylesheet" href="site-lib/styles/supported-plugins.css"></noscript><link rel="preload" href="site-lib/styles/main-styles.css" as="style" onload="this.onload=null;this.rel='stylesheet'"><noscript><link rel="stylesheet" href="site-lib/styles/main-styles.css"></noscript><style>body{--line-width:40em;--line-width-adaptive:40em;--file-line-width:40em;--sidebar-width:min(20em, 80vw);--collapse-arrow-size:11px;--tree-vertical-spacing:1.3em;--sidebar-margin:12px}:root{background-color:#202124}.sidebar{height:100%;font-size:14px;z-index:10;min-width:calc(var(--sidebar-width) + var(--divider-width-hover));max-width:calc(var(--sidebar-width) + var(--divider-width-hover));position:relative;overflow:hidden;overflow:clip;transition:min-width ease-in-out,max-width ease-in-out;transition-duration:.2s;contain:size}#left-sidebar{left:0}#right-sidebar{right:0}.sidebar.is-collapsed{min-width:0;max-width:0}.sidebar.floating{position:absolute}.sidebar .leaf-content{height:100%;min-width:calc(var(--sidebar-width) - var(--divider-width-hover));top:0;padding:var(--sidebar-margin);padding-top:4em;line-height:var(--line-height-tight);background-color:var(--background-secondary);transition:background-color,border-right,border-left,box-shadow;transition-duration:var(--color-fade-speed);transition-timing-function:ease-in-out;position:absolute;display:flex;flex-direction:column}.sidebar:not(.is-collapsed) .leaf-content{min-width:calc(max(100%,var(--sidebar-width)) - 3px);max-width:calc(max(100%,var(--sidebar-width)) - 3px)}#left-sidebar-content{left:0;border-top-right-radius:var(--radius-l);border-bottom-right-radius:var(--radius-l)}#right-sidebar-content{right:0;border-top-left-radius:var(--radius-l);border-bottom-left-radius:var(--radius-l)}.sidebar #left-sidebar-content,.sidebar #right-sidebar-content{contain:none!important;container-type:normal!important;animation:none!important}.sidebar:has(.leaf-content:empty):has(.topbar-content:empty){display:none}.sidebar-topbar{height:calc(2.3em + 2 * var(--sidebar-margin));width:var(--sidebar-width);padding:var(--sidebar-margin);z-index:1;position:fixed;display:flex;align-items:center;transition:width ease-in-out;transition-duration:inherit}.sidebar.is-collapsed .sidebar-topbar{width:calc(2.3em + var(--sidebar-margin) * 2)}.sidebar .sidebar-topbar.is-collapsed{width:0}#left-sidebar .sidebar-topbar{left:0;flex-direction:row;border-top-right-radius:var(--radius-l)}#right-sidebar .sidebar-topbar{right:0;flex-direction:row-reverse;border-top-left-radius:var(--radius-l)}#left-sidebar .topbar-content{margin-right:calc(2.3em + var(--sidebar-margin));flex-direction:row}#right-sidebar .topbar-content{margin-left:calc(2.3em + var(--sidebar-margin));flex-direction:row-reverse}.topbar-content{overflow:hidden visible;overflow:clip visible;width:100%;height:100%;display:flex;align-items:center;transition:inherit}.sidebar.is-collapsed .topbar-content{width:0;transition:inherit}.clickable-icon.sidebar-collapse-icon{background-color:transparent;color:var(--icon-color-focused);padding:2px!important;margin:0!important;height:100%!important;width:2.3em!important;margin-inline:0.14em!important;position:absolute}#left-sidebar .clickable-icon.sidebar-collapse-icon{transform:rotateY(180deg);right:var(--sidebar-margin)}#right-sidebar .clickable-icon.sidebar-collapse-icon{transform:rotateY(180deg);left:var(--sidebar-margin)}.clickable-icon.sidebar-collapse-icon svg.svg-icon{width:100%;height:100%}.feature-title{margin-left:1px;text-transform:uppercase;letter-spacing:.06em;margin-top:.75em;margin-bottom:.75em}.feature-header{display:flex;align-items:center;padding-top:0;font-size:1em;padding-left:0}body.floating-sidebars .sidebar{position:absolute}body{transition:background-color var(--color-fade-speed) ease-in-out}#navbar:not(:empty){display:flex;align-items:center;justify-content:space-between;padding:.5em 1em;width:100%}#main{display:flex;flex-direction:column;height:100%;width:100%;align-items:stretch;justify-content:center}#main-horizontal{display:flex;flex-direction:row;flex-grow:1;width:100%;align-items:stretch;justify-content:center}#center-content{flex-basis:100%;max-width:100%;width:100%;height:100%;display:flex;flex-direction:column;align-items:center;transition:opacity .2s ease-in-out;contain:inline-size}.hide{opacity:0!important;transition:opacity .2s ease-in-out;pointer-events:none}#center-content>.obsidian-document{padding-left:2em;padding-right:1em;margin-bottom:0;width:100%;width:-webkit-fill-available;width:-moz-available;width:fill-available;transition:background-color var(--color-fade-speed) ease-in-out;border-top-right-radius:var(--window-radius,var(--radius-m));border-top-left-radius:var(--window-radius,var(--radius-m));overflow-x:hidden!important;overflow-y:auto!important;display:flex!important;flex-direction:column!important;align-items:center!important;contain:inline-size}body #center-content>.obsidian-document>.markdown-preview-sizer{padding-bottom:80vh;width:100%;max-width:var(--line-width);flex-basis:var(--line-width);transition:background-color var(--color-fade-speed) ease-in-out;contain:inline-size}#center-content>.obsidian-document>div{width:100%!important;transition:background-color var(--color-fade-speed) ease-in-out;contain:inline-size}#center-content>.obsidian-document:not([data-type=markdown]).embed{display:flex;padding:1em;height:100%;width:100%;align-items:center;justify-content:center}#center-content>.obsidian-document:not([data-type=markdown]).embed>*{max-width:100%;max-height:100%;object-fit:contain}:not(h1,h2,h3,h4,h5,h6,li):has(> :is(.math,table)){overflow-x:auto!important}#center-content>.obsidian-document:not([data-type=markdown]){overflow-x:auto;contain:content;padding:0;margin:0;height:100%}.obsidian-document[data-type=attachment]{display:flex;flex-direction:column;align-items:center;justify-content:center;height:100%;width:100%}.obsidian-document[data-type=attachment]>*{outline:0;border:none;box-shadow:none}.obsidian-document[data-type=attachment] :is(img){max-width:90%;max-height:90%;object-fit:contain}.obsidian-document[data-type=attachment]>:is(audio){width:100%;max-width:min(90%,var(--line-width))}.obsidian-document[data-type=attachment]>:is(embed,iframe,video){width:100%;height:100%;max-width:100%;max-height:100%;object-fit:contain}.canvas-wrapper>:is(.header,.footer){z-index:100;position:absolute;display:flex;justify-content:center;flex-direction:column;width:100%;align-items:center}.scroll-highlight{position:absolute;width:100%;height:100%;pointer-events:none;z-index:1000;background-color:hsla(var(--color-accent-hsl),.25);opacity:0;padding:1em;inset:50%;translate:-50% -50%;border-radius:var(--radius-s)}</style><script defer="">async function loadIncludes(){let e=document.querySelectorAll("link[itemprop='include']");for(const t of e){let e=t.getAttribute("href");try{let o="";if(e.startsWith("https:")||e.startsWith("http:")||"file:"!=window.location.protocol){const n=await fetch(e);if(!n.ok){console.log("Could not include file: "+e),t?.remove();continue}o=await n.text()}else{const t=document.getElementById(btoa(encodeURI(e)));if(t){const e=JSON.parse(decodeURI(atob(t.getAttribute("value")??"")));o=e?.data??""}}let n=document.createRange().createContextualFragment(o);t.before(n),t.remove(),console.log("Included text: "+o),console.log("Included file: "+e)}catch(o){t?.remove(),console.log("Could not include file: "+e,o);continue}}}document.addEventListener("DOMContentLoaded",(()=>{loadIncludes()}));let isFileProtocol="file:"==location.protocol;function waitLoadScripts(e,t){let o=e.map((e=>document.getElementById(e+"-script")));!function e(n){let l=o[n],c=n+1;l?(l&&"true"!=l.getAttribute("loaded")||n<o.length&&e(c),n<o.length&&l.addEventListener("load",(()=>e(c)))):n<o.length?e(c):t()}(0)}</script></head><body class="publish css-settings-manager is-frameless is-hidden-frameless styled-scrollbars show-inline-title show-ribbon is-focused"><script defer="">let theme=localStorage.getItem("theme")||(window.matchMedia("(prefers-color-scheme: dark)").matches?"dark":"light");"dark"==theme?(document.body.classList.add("theme-dark"),document.body.classList.remove("theme-light")):(document.body.classList.add("theme-light"),document.body.classList.remove("theme-dark")),window.innerWidth<480?document.body.classList.add("is-phone"):window.innerWidth<768?document.body.classList.add("is-tablet"):window.innerWidth<1024?document.body.classList.add("is-small-screen"):document.body.classList.add("is-large-screen")</script><div class="parsed-feature-container" style="display: contents;"><link itemprop="include" href="site-lib/html/custom-head-content-content.html"></div><div id="main"><div id="navbar"></div><div id="main-horizontal"><div id="left-content" class="leaf" style="--sidebar-width: var(--sidebar-width-left);"><div id="left-sidebar" class="sidebar"><div class="sidebar-handle"></div><div class="sidebar-topbar"><div class="topbar-content"><div id="search-container"><div id="search-wrapper"><input enterkeyhint="search" type="search" spellcheck="false" placeholder="Search..."><div aria-label="Clear search" id="search-clear-button"></div></div></div></div><div class="clickable-icon sidebar-collapse-icon"><svg xmlns="http://www.w3.org/2000/svg" width="100%" height="100%" viewBox="0 0 24 24" fill="none" stroke="currentColor" stroke-width="3" stroke-linecap="round" stroke-linejoin="round" class="svg-icon"><path d="M21 3H3C1.89543 3 1 3.89543 1 5V19C1 20.1046 1.89543 21 3 21H21C22.1046 21 23 20.1046 23 19V5C23 3.89543 22.1046 3 21 3Z"></path><path d="M10 4V20"></path><path d="M4 7H7"></path><path d="M4 10H7"></path><path d="M4 13H7"></path></svg></div></div><div class="sidebar-content-wrapper"><div id="left-sidebar-content" class="leaf-content"><link itemprop="include" href="site-lib/html/file-tree-content.html"></div></div><script defer="">let ls = document.querySelector("#left-sidebar"); ls.classList.toggle("is-collapsed", window.innerWidth < 768); ls.style.setProperty("--sidebar-width", localStorage.getItem("sidebar-left-width"));</script></div></div><div id="center-content" class="leaf"><div class="obsidian-document markdown-preview-view markdown-rendered node-insert-event is-readable-line-width allow-fold-headings allow-fold-lists show-indentation-guide show-properties" data-type="markdown"><style id="MJX-CHTML-styles"></style><div class="markdown-preview-sizer markdown-preview-section"><div class="header"><h1 class="page-title heading inline-title" id="deep-research-report_0">deep-research-report</h1><div class="data-bar"></div></div><div class="markdown-preview-pusher" style="width: 1px; height: 0.1px; margin-bottom: 0px;"></div><div class="el-h1"><h1 data-heading="Criação de Agente de IA Local com Ollama e Base de Conhecimento em Markdown" dir="auto" class="heading" id="Criação_de_Agente_de_IA_Local_com_Ollama_e_Base_de_Conhecimento_em_Markdown_0"><span class="heading-collapse-indicator collapse-indicator collapse-icon"><svg xmlns="http://www.w3.org/2000/svg" width="24" height="24" viewBox="0 0 24 24" fill="none" stroke="currentColor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round" class="svg-icon right-triangle"><path d="M3 8L12 17L21 8"></path></svg></span>Criação de Agente de IA Local com Ollama e Base de Conhecimento em Markdown</h1></div><div class="el-h2"><h2 data-heading="Resumo Executivo" dir="auto" class="heading" id="Resumo_Executivo_0"><span class="heading-collapse-indicator collapse-indicator collapse-icon"><svg xmlns="http://www.w3.org/2000/svg" width="24" height="24" viewBox="0 0 24 24" fill="none" stroke="currentColor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round" class="svg-icon right-triangle"><path d="M3 8L12 17L21 8"></path></svg></span>Resumo Executivo</h2></div><div class="el-p"><p dir="auto">Este relatório detalha como montar um agente de IA conversacional <strong>local</strong> usando <a data-tooltip-position="top" aria-label="https://ollama.com" rel="noopener nofollow" class="external-link is-unresolved" href="https://ollama.com" target="_self">Ollama</a> e arquivos Markdown como fonte de conhecimento. Abordamos desde requisitos de hardware/software, passando por instalação do Ollama, seleção de modelos, até a configuração do pipeline RAG (Retrieval-Augmented Generation). Em seguida descrevemos ingestão e indexação dos documentos Markdown, mecanismos de busca (BM25 e vetorial), arquitetura de diálogo, exemplos de código (Linux/macOS/Windows), esquemas de dados, avaliação, deploy e manutenção. Citamos boas práticas, riscos (licenças, viés, segurança) e fornecemos diagramas (Mermaid) e tabelas comparativas quando útil. Este guia supõe certo conhecimento técnico do usuário (terminal, Python, etc.) e foca em soluções <strong>open-source</strong> e locais, dando preferência a fontes oficiais e, quando possível, materiais em português.</p></div><div class="el-h2"><h2 data-heading="1. Requisitos de Hardware e Software" dir="auto" class="heading" id="1._Requisitos_de_Hardware_e_Software_0"><span class="heading-collapse-indicator collapse-indicator collapse-icon"><svg xmlns="http://www.w3.org/2000/svg" width="24" height="24" viewBox="0 0 24 24" fill="none" stroke="currentColor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round" class="svg-icon right-triangle"><path d="M3 8L12 17L21 8"></path></svg></span>1. Requisitos de Hardware e Software</h2></div><div class="el-table" dir="ltr" style="overflow-x: auto;"><table>
<thead>
<tr>
<th dir="ltr">Componente</th>
<th dir="ltr">Recomendação Mínima</th>
<th dir="ltr">Observação</th>
</tr>
</thead>
<tbody>
<tr>
<td dir="ltr"><strong>Sistema Operacional</strong></td>
<td dir="ltr">Linux (Ubuntu&nbsp;22.04+), Windows&nbsp;10/11 (22H2+), macOS Sonoma (v14)+【11†L418-L424】【17†L91-L94】</td>
<td dir="ltr">(Intel no Mac = CPU-only)</td>
</tr>
<tr>
<td dir="ltr"><strong>CPU</strong></td>
<td dir="ltr">≥4 núcleos x86_64 modernos【11†L422-L424】</td>
<td dir="ltr">(≥8 núcleos p/ modelos ≥13B)【11†L422-L424】</td>
</tr>
<tr>
<td dir="ltr"><strong>Memória (RAM)</strong></td>
<td dir="ltr">≥16&nbsp;GB【11†L417-L424】</td>
<td dir="ltr">(32&nbsp;GB+ recomendado)</td>
</tr>
<tr>
<td dir="ltr"><strong>Armazenamento</strong></td>
<td dir="ltr">≥12&nbsp;GB (sistema + básicos)【11†L419-L422】 + espaço extra para modelos (pode chegar a centenas de GB)</td>
<td dir="ltr">(disco SSD preferível)</td>
</tr>
<tr>
<td dir="ltr"><strong>GPU (opcional)</strong></td>
<td dir="ltr">NVIDIA com Compute Capability ≥5.0 (driver ≥531)【5†L91-L100】 ou AMD com ROCm</td>
<td dir="ltr">Acelera modelos grandes; sem GPU roda em CPU</td>
</tr>
<tr>
<td dir="ltr"><strong>VRAM</strong></td>
<td dir="ltr">Depende do modelo (ex.: 8B ≈ 5–8&nbsp;GB, 27B ≈ 12–16&nbsp;GB, 70B ≈ 40&nbsp;GB)【42†L174-L183】【19†L334-L339】</td>
<td dir="ltr">Recomendação: modelo ≤ 2/3 da VRAM disponível【11†L482-L485】</td>
</tr>
<tr>
<td dir="ltr"><strong>Bibliotecas</strong></td>
<td dir="ltr">Python&nbsp;3.8+, Docker (se usar Milvus), ferramentas de indexação (FAISS, Chroma, etc.)</td>
<td dir="auto"></td>
</tr>
</tbody>
</table></div><div class="el-p"><p dir="auto">As exigências podem variar conforme o modelo e task. Por exemplo, para rodar <strong>modelos 7–13B</strong> recomenda-se ≳16&nbsp;GB de RAM【11†L482-L485】. GPUs aceleram o processamento; como referência, um modelo de <strong>8&nbsp;GB</strong> requer ~12&nbsp;GB VRAM【11†L482-L485】. Sem GPU, o tempo de resposta aumenta.</p></div><div class="el-h2"><h2 data-heading="2. Instalação e Configuração do Ollama" dir="auto" class="heading" id="2._Instalação_e_Configuração_do_Ollama_0"><span class="heading-collapse-indicator collapse-indicator collapse-icon"><svg xmlns="http://www.w3.org/2000/svg" width="24" height="24" viewBox="0 0 24 24" fill="none" stroke="currentColor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round" class="svg-icon right-triangle"><path d="M3 8L12 17L21 8"></path></svg></span>2. Instalação e Configuração do Ollama</h2></div><div class="el-p"><p dir="auto"><strong>Ollama</strong> fornece binários prontos para Linux, Windows e macOS【11†L417-L422】【17†L91-L94】.  </p></div><div class="el-ul"><ul class="has-list-bullet">
<li data-line="0" dir="auto"><span class="list-bullet"></span>
<p><strong>Linux</strong>: execute no terminal:  </p>
<pre class="language-bash"><code data-line="1" class="language-bash is-loaded"><span class="token function">curl</span> <span class="token parameter variable">-fsSL</span> https://ollama.com/install.sh <span class="token operator">|</span> <span class="token function">sh</span>
</code><button class="copy-code-button"><svg xmlns="http://www.w3.org/2000/svg" width="24" height="24" viewBox="0 0 24 24" fill="none" stroke="currentColor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round" class="svg-icon lucide-copy"><rect x="8" y="8" width="14" height="14" rx="2" ry="2"></rect><path d="M4 16c-1.1 0-2-.9-2-2V4c0-1.1.9-2 2-2h10c1.1 0 2 .9 2 2"></path></svg></button></pre>
<p>Isso instala o serviço. Em seguida, inicie o servidor:  </p>
<pre class="language-bash"><code data-line="5" class="language-bash is-loaded">ollama serve
</code><button class="copy-code-button"><svg xmlns="http://www.w3.org/2000/svg" width="24" height="24" viewBox="0 0 24 24" fill="none" stroke="currentColor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round" class="svg-icon lucide-copy"><rect x="8" y="8" width="14" height="14" rx="2" ry="2"></rect><path d="M4 16c-1.1 0-2-.9-2-2V4c0-1.1.9-2 2-2h10c1.1 0 2 .9 2 2"></path></svg></button></pre>
<p>(Opcional: crie um serviço systemd para iniciar automaticamente【15†L149-L157】【15†L177-L184】.) Para acelerar com GPU NVIDIA, ative <em>FlashAttention</em> via variável:  </p>
<pre class="language-bash"><code data-line="9" class="language-bash is-loaded"><span class="token builtin class-name">export</span> <span class="token assign-left variable">OLLAMA_FLASH_ATTENTION</span><span class="token operator">=</span><span class="token number">1</span>  <span class="token comment"># reduz latência de tokens【11†L482-L485】 </span>
</code><button class="copy-code-button"><svg xmlns="http://www.w3.org/2000/svg" width="24" height="24" viewBox="0 0 24 24" fill="none" stroke="currentColor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round" class="svg-icon lucide-copy"><rect x="8" y="8" width="14" height="14" rx="2" ry="2"></rect><path d="M4 16c-1.1 0-2-.9-2-2V4c0-1.1.9-2 2-2h10c1.1 0 2 .9 2 2"></path></svg></button></pre>
</li>
<li data-line="13" dir="auto"><span class="list-bullet"></span>
<p><strong>Windows</strong>: baixe o instalador (<code>OllamaSetup.exe</code>). Não requer administrador e instala no diretório do usuário【16†L110-L118】. Após instalação, o comando <code>ollama</code> fica disponível em cmd/PowerShell e o servidor roda em background ouvindo em <code>http://localhost:11434</code>【16†L89-L97】【16†L110-L118】. É possível trocar pastas padrão com a variável de ambiente <code>OLLAMA_MODELS</code>【16†L132-L142】. Exemplo de chamada da API em PowerShell:  </p>
<pre class="language-powershell"><code data-line="14" class="language-powershell is-loaded"><span class="token punctuation">(</span><span class="token function">Invoke-WebRequest</span> <span class="token operator">-</span>Method POST <span class="token operator">-</span>Body <span class="token string">'{"model":"gemma3", "prompt":"Olá, mundo!", "stream":false}'</span> <span class="token operator">-</span>Uri http:<span class="token operator">/</span><span class="token operator">/</span>localhost:11434/api/generate<span class="token punctuation">)</span><span class="token punctuation">.</span>Content
</code><button class="copy-code-button"><svg xmlns="http://www.w3.org/2000/svg" width="24" height="24" viewBox="0 0 24 24" fill="none" stroke="currentColor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round" class="svg-icon lucide-copy"><rect x="8" y="8" width="14" height="14" rx="2" ry="2"></rect><path d="M4 16c-1.1 0-2-.9-2-2V4c0-1.1.9-2 2-2h10c1.1 0 2 .9 2 2"></path></svg></button></pre>
</li>
<li data-line="18" dir="auto"><span class="list-bullet"></span>
<p><strong>macOS</strong>: monte o <code>ollama.dmg</code> e mova para <code>/Applications</code>. Requer macOS Sonoma e CPU Apple M ou Intel【17†L91-L94】. Na 1ª execução, autorize a criação de <code>ollama</code> no PATH【17†L100-L107】. O CLI funciona em qualquer terminal. Espaço: ~4&nbsp;GB para o app + modelos (pode ser em outra pasta).  </p>
</li>
</ul></div><div class="el-p"><p dir="auto">Após instalar, confira:  </p></div><div class="el-pre"><pre class="language-bash"><code data-line="0" class="language-bash is-loaded">ollama <span class="token parameter variable">-v</span>   <span class="token comment"># versão do Ollama</span>
ollama list <span class="token comment"># lista modelos disponíveis/localizados</span>
</code><button class="copy-code-button"><svg xmlns="http://www.w3.org/2000/svg" width="24" height="24" viewBox="0 0 24 24" fill="none" stroke="currentColor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round" class="svg-icon lucide-copy"><rect x="8" y="8" width="14" height="14" rx="2" ry="2"></rect><path d="M4 16c-1.1 0-2-.9-2-2V4c0-1.1.9-2 2-2h10c1.1 0 2 .9 2 2"></path></svg></button></pre></div><div class="el-p"><p dir="auto">Para baixar modelos, use <code>ollama run</code> ou <code>ollama pull</code>. Por exemplo:  </p></div><div class="el-pre"><pre class="language-bash"><code data-line="0" class="language-bash is-loaded">ollama run llama3.2       <span class="token comment"># instala e inicia modelo Llama3.2 (3B)【42†L169-L174】</span>
ollama pull gemma2:27b   <span class="token comment"># baixa Gemma2 (27B) sem iniciar</span>
</code><button class="copy-code-button"><svg xmlns="http://www.w3.org/2000/svg" width="24" height="24" viewBox="0 0 24 24" fill="none" stroke="currentColor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round" class="svg-icon lucide-copy"><rect x="8" y="8" width="14" height="14" rx="2" ry="2"></rect><path d="M4 16c-1.1 0-2-.9-2-2V4c0-1.1.9-2 2-2h10c1.1 0 2 .9 2 2"></path></svg></button></pre></div><div class="el-blockquote"><blockquote dir="auto">
<p><strong>Recomendação:</strong> Modelo selecionado deve ter no máximo ~50–70% da VRAM disponível【11†L482-L485】 e RAM suficiente (ex.: modelo 13B ≳32&nbsp;GB RAM【11†L482-L485】).  </p>
</blockquote></div><div class="el-h2"><h2 data-heading="3. Modelos Compatíveis (Comparativo)" dir="auto" class="heading" id="3._Modelos_Compatíveis_(Comparativo)_0"><span class="heading-collapse-indicator collapse-indicator collapse-icon"><svg xmlns="http://www.w3.org/2000/svg" width="24" height="24" viewBox="0 0 24 24" fill="none" stroke="currentColor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round" class="svg-icon right-triangle"><path d="M3 8L12 17L21 8"></path></svg></span>3. Modelos Compatíveis (Comparativo)</h2></div><div class="el-p"><p dir="auto">O Ollama inclui diversos <strong>modelos open-source</strong>. A tabela abaixo resume alguns populares:</p></div><div class="el-table" dir="ltr" style="overflow-x: auto;"><table>
<thead>
<tr>
<th dir="ltr">Modelo</th>
<th dir="ltr">Parâmetros</th>
<th dir="ltr">Tamanho (quantiz.)</th>
<th dir="ltr">VRAM (8-bit)</th>
<th dir="ltr">Licença</th>
<th dir="ltr">Prós/Contras</th>
</tr>
</thead>
<tbody>
<tr>
<td dir="ltr"><strong>Llama 3.2</strong></td>
<td dir="ltr">1B, 3B</td>
<td dir="ltr">~1.3GB, 2.0GB【42†L169-L174】</td>
<td dir="ltr">~2–3GB (1B)</td>
<td dir="ltr">Licença Llama 3 (meta)</td>
<td dir="ltr">Versátil, boa performance geral; licença restrita (uso comercial?)</td>
</tr>
<tr>
<td dir="ltr"><strong>Llama 3.1</strong></td>
<td dir="ltr">8B, 70B, 405B</td>
<td dir="ltr">4.7GB, 40GB, 231GB【42†L174-L177】</td>
<td dir="ltr">8B≈4.6GB【20†L432-L440】, 70B≈40GB【42†L174-L177】</td>
<td dir="ltr">Licença Llama 3</td>
<td dir="ltr">Qualidade líder; modelos muito grandes demandam multi-GPU【36†L100-L108】</td>
</tr>
<tr>
<td dir="ltr"><strong>Mistral</strong></td>
<td dir="ltr">7B</td>
<td dir="ltr">~4.1GB【42†L179-L183】</td>
<td dir="ltr">~4GB (7B)</td>
<td dir="ltr">Apache&nbsp;2.0</td>
<td dir="ltr">Eficiente e de alto desempenho; leve (&lt;8GB VRAM)【42†L179-L183】</td>
</tr>
<tr>
<td dir="ltr"><strong>Gemma&nbsp;2/3</strong></td>
<td dir="ltr">2B, 9B, 27B / 12B, 27B</td>
<td dir="ltr">1.6GB, 5.5GB, 16GB【42†L179-L183】</td>
<td dir="ltr">27B≈16GB【42†L179-L183】</td>
<td dir="ltr">Licença Gemma</td>
<td dir="ltr">Alta performance, bem ajustado a contextos longos; 27B ~16GB VRAM【42†L179-L183】</td>
</tr>
<tr>
<td dir="ltr"><strong>Qwen&nbsp;2/Qwen&nbsp;3</strong></td>
<td dir="ltr">0.5B–72B / 0.6B–235B</td>
<td dir="auto">—</td>
<td dir="ltr">72B≈42GB【36†L116-L119】, 235B (MoE) ≫60GB【36†L100-L108】</td>
<td dir="ltr">Apache&nbsp;2.0</td>
<td dir="ltr">Suporte 128k tokens, multilingue; modelos grandes exigem multi-GPU【36†L100-L108】</td>
</tr>
<tr>
<td dir="ltr"><strong>Falcon</strong></td>
<td dir="ltr">7B, 40B</td>
<td dir="ltr">3.8GB (7B), 25GB (40B) (aprox.)</td>
<td dir="ltr">~4GB (7B)</td>
<td dir="ltr">Apache&nbsp;2.0</td>
<td dir="ltr">Bom para codificação; Falcon-7B leve, 40B requer ~25GB.</td>
</tr>
<tr>
<td dir="ltr"><strong>Phi-3 (Mini/Med)</strong></td>
<td dir="ltr">3.8B, 14B</td>
<td dir="ltr">2.3GB, 7.9GB【42†L177-L181】</td>
<td dir="ltr">3B≈2.3GB, 14B≈7.9GB【42†L177-L181】</td>
<td dir="ltr">Apache&nbsp;2.0 (MICROSOFT)</td>
<td dir="ltr">Alta eficiência em tarefas de raciocínio de Python, leve.</td>
</tr>
<tr>
<td dir="ltr"><strong>Outros</strong></td>
<td dir="ltr">Llama&nbsp;2, CodeLlama, Falcon2, Orca-mini, etc.</td>
<td dir="ltr">variado</td>
<td dir="ltr">variado</td>
<td dir="ltr">variado (Apache, CC-BY-NC, etc.)</td>
<td dir="ltr">Depende do caso de uso; some são específicos (codificação, visão, etc.).</td>
</tr>
</tbody>
</table></div><div class="el-blockquote"><blockquote dir="auto">
<p><em>Exemplo:</em> Llama&nbsp;3.1 (70B) necessita ~40 GB de VRAM【42†L174-L177】, enquanto Gemma&nbsp;2 (27B) requer ~16 GB【42†L179-L183】. O HuggingFace destaca que modelos como Qwen-3 (235B MoE) só cabem em configurações multi-GPU【36†L100-L108】. Licenças variam: muitos usam Apache&nbsp;2.0【36†L100-L108】 (uso comercial livre), mas alguns (Llama 3, Gemma) têm licenças próprias. Consulte a documentação de cada modelo.</p>
</blockquote></div><div class="el-p"><p dir="auto"><strong>Observações:</strong>  </p></div><div class="el-ul"><ul class="has-list-bullet">
<li data-line="0" dir="auto"><span class="list-bullet"></span>Modelos quantizados (4/8-bit) reduzem RAM/VRAM em ~4×, com ~1–2% de perda de precisão【44†L214-L219】.  </li>
<li data-line="1" dir="auto"><span class="list-bullet"></span>Para fine-tuning, recomenda-se versões menores (≤3B) e LoRA (abaixo)【45†L7-L10】.  </li>
<li data-line="2" dir="auto"><span class="list-bullet"></span>O Ollama permite importar modelos via GGUF ou safetensors (veja <em>Modelfile</em>【42†L196-L204】).  </li>
</ul></div><div class="el-h2"><h2 data-heading="4. Treinamento e Ajustes (Fine-Tuning)" dir="auto" class="heading" id="4._Treinamento_e_Ajustes_(Fine-Tuning)_0"><span class="heading-collapse-indicator collapse-indicator collapse-icon"><svg xmlns="http://www.w3.org/2000/svg" width="24" height="24" viewBox="0 0 24 24" fill="none" stroke="currentColor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round" class="svg-icon right-triangle"><path d="M3 8L12 17L21 8"></path></svg></span>4. Treinamento e Ajustes (Fine-Tuning)</h2></div><div class="el-p"><p dir="auto">Para personalizar o modelo ao domínio da sua base de conhecimento, é possível <strong>afinar o modelo (fine-tuning)</strong> ou usar adaptadores LoRA.  </p></div><div class="el-ul"><ul class="has-list-bullet">
<li data-line="0" dir="auto"><span class="list-bullet"></span><strong>Fine-tuning clássico:</strong> requer GPU potente e muito tempo. Pode ser feito com bibliotecas como <a data-tooltip-position="top" aria-label="https://peft.ai/" rel="noopener nofollow" class="external-link is-unresolved" href="https://peft.ai/" target="_self">PEFT</a> ou <a data-tooltip-position="top" aria-label="https://github.com/lvwerra/trl" rel="noopener nofollow" class="external-link is-unresolved" href="https://github.com/lvwerra/trl" target="_self">trl</a>.  </li>
<li data-line="1" dir="auto"><span class="list-bullet"></span><strong>LoRA (Low-Rank Adaptation):</strong> técnica popular que insere matrizes pequenas treináveis no modelo, reduzindo parâmetros atualizados. Permite treinar em GPUs menores. A literatura indica que LoRA em modelos quantizados (4-bit) supera o fine-tuning completo【46†L4-L11】. (Ex.: adaptar em uma GPU de 16 GB usando quantização 4-bit【44†L214-L219】.)  </li>
<li data-line="2" dir="auto"><span class="list-bullet"></span><strong>Quantização:</strong> Converter pesos para 8-bit ou 4-bit reduz drasticamente uso de memória【44†L214-L219】. Por exemplo, treinar em 4-bit ocupa 4× menos memória, permitindo usar GPUs de 16 GB【44†L214-L219】 (com ~1–2% de perda de acurácia). Para inferência, quantizações 8-bit/4-bit comuns (e.g. GGUF Q4_K_M, Q8) aceleram a execução. Ollama suporta modelos quantizados nativamente (v. table acima).  </li>
</ul></div><div class="el-p"><p dir="auto"><strong>Uso de embeddings:</strong> O Ollama inclui modelos de embeddings (ex.: <code>embeddinggemma</code>, <code>qwen3-embedding</code>, <code>all-minilm</code>)【38†L97-L105】. Com eles, transforme textos em vetores para indexação. Exemplo de comando para gerar embedding via API:  </p></div><div class="el-pre"><pre class="language-bash"><code data-line="0" class="language-bash is-loaded"><span class="token function">curl</span> <span class="token parameter variable">-X</span> POST http://localhost:11434/api/embed <span class="token punctuation">\</span>
  <span class="token parameter variable">-H</span> <span class="token string">"Content-Type: application/json"</span> <span class="token punctuation">\</span>
  <span class="token parameter variable">-d</span> <span class="token string">'{"model": "embeddinggemma", "input": "Exemplo de texto."}'</span>
</code><button class="copy-code-button"><svg xmlns="http://www.w3.org/2000/svg" width="24" height="24" viewBox="0 0 24 24" fill="none" stroke="currentColor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round" class="svg-icon lucide-copy"><rect x="8" y="8" width="14" height="14" rx="2" ry="2"></rect><path d="M4 16c-1.1 0-2-.9-2-2V4c0-1.1.9-2 2-2h10c1.1 0 2 .9 2 2"></path></svg></button></pre></div><div class="el-p"><p dir="auto">Isso retorna um vetor JSON (normalizado)【38†L125-L133】. Em Python, use <code>ollama.embed(...)</code>【38†L139-L146】. Mantenha o mesmo modelo de embedding para indexar documentos e consultar.</p></div><div class="el-h2"><h2 data-heading="5. Pipeline de Ingestão e Indexação de Markdown" dir="auto" class="heading" id="5._Pipeline_de_Ingestão_e_Indexação_de_Markdown_0"><span class="heading-collapse-indicator collapse-indicator collapse-icon"><svg xmlns="http://www.w3.org/2000/svg" width="24" height="24" viewBox="0 0 24 24" fill="none" stroke="currentColor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round" class="svg-icon right-triangle"><path d="M3 8L12 17L21 8"></path></svg></span>5. Pipeline de Ingestão e Indexação de Markdown</h2></div><div class="el-p"><p dir="auto">Para usar seus arquivos Markdown como KB, siga estes passos:</p></div><div class="el-ol"><ol>
<li data-line="0" dir="auto">
<p><strong>Pré-processamento:</strong> Converta Markdown em texto plano (remova sintaxe, imagens) preservando títulos/metadados. Pode usar ferramentas como <code>markdown-it</code> (Node), <code>python-markdown</code>, ou o <a data-tooltip-position="top" aria-label="https://github.com/kevwan/rag-agent" rel="noopener nofollow" class="external-link is-unresolved" href="https://github.com/kevwan/rag-agent" target="_self">Doc2Vec</a> deste exemplo. Extraia <em>front-matter</em> YAML ou metadados (título, tags).  </p>
</li>
<li data-line="1" dir="auto">
<p><strong>Chunking:</strong> Divida documentos longos em blocos menores (~200–500 tokens). Por exemplo, quebre por parágrafos ou use métodos semânticos (sliding windows). Isso melhora a granularidade da busca.  </p>
</li>
<li data-line="2" dir="auto">
<p><strong>Indexação Vetorial:</strong> Para cada chunk, gere embedding (como acima) e armazene em um banco vetorial. A exemplo do <a data-tooltip-position="top" aria-label="https://github.com/kevwan/rag-agent" rel="noopener nofollow" class="external-link is-unresolved" href="https://github.com/kevwan/rag-agent" target="_self">Markdown Knowledge RAG</a>:  </p>
<pre class="language-bash"><code data-line="3" class="language-bash is-loaded">python doc2vec.py <span class="token parameter variable">--dir</span> /caminho/markdown <span class="token parameter variable">--model</span> embeddinggemma
</code><button class="copy-code-button"><svg xmlns="http://www.w3.org/2000/svg" width="24" height="24" viewBox="0 0 24 24" fill="none" stroke="currentColor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round" class="svg-icon lucide-copy"><rect x="8" y="8" width="14" height="14" rx="2" ry="2"></rect><path d="M4 16c-1.1 0-2-.9-2-2V4c0-1.1.9-2 2-2h10c1.1 0 2 .9 2 2"></path></svg></button></pre>
<p>(Esse script usa Ollama e Milvus para vetorização.) Obtenha assim uma coleção indexada. Ferramentas recomendadas: <strong>Chroma</strong>, <strong>FAISS</strong>, <strong>Milvus</strong> ou <strong>Qdrant</strong>.  </p>
</li>
<li data-line="8" dir="auto">
<p><strong>Indexação de texto (BM25):</strong> Opcionalmente, crie também um índice de texto completo (ex.: Whoosh, Lucene) para buscas por palavra-chave (BM25). Isso permite <em>hybrid search</em> (ver próximo item).  </p>
</li>
<li data-line="10" dir="auto">
<p><strong>Serviço de busca:</strong> Instale e configure seu vetor DB. Exemplo com <strong>Milvus</strong> via Docker:  </p>
<pre class="language-bash"><code data-line="11" class="language-bash is-loaded"><span class="token function">docker</span> run <span class="token parameter variable">-d</span> <span class="token parameter variable">--name</span> milvus-standalone <span class="token parameter variable">-p</span> <span class="token number">19530</span>:19530 milvusdb/milvus:latest
</code><button class="copy-code-button"><svg xmlns="http://www.w3.org/2000/svg" width="24" height="24" viewBox="0 0 24 24" fill="none" stroke="currentColor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round" class="svg-icon lucide-copy"><rect x="8" y="8" width="14" height="14" rx="2" ry="2"></rect><path d="M4 16c-1.1 0-2-.9-2-2V4c0-1.1.9-2 2-2h10c1.1 0 2 .9 2 2"></path></svg></button></pre>
<p>Em seguida, o pipeline Python conecta ao host (p.ex. <code>localhost:19530</code>) e insere vetores. Confira <a data-tooltip-position="top" aria-label="https://milvus.io/docs" rel="noopener nofollow" class="external-link is-unresolved" href="https://milvus.io/docs" target="_self">Milvus docs</a> para detalhes.  </p>
</li>
</ol></div><div class="el-p"><p dir="auto">Abaixo um diagrama simplificado do fluxo de dados de indexação e consulta:</p></div><div class="el-pre"><pre class="language-mermaid"><code data-line="0" class="language-mermaid is-loaded">Error parsing Mermaid diagram!

Parse error on line 4:
...-&gt; D[Banco Vetorial (FAISS/Milvus/Chroma
-----------------------^
Expecting 'SQE', 'DOUBLECIRCLEEND', 'PE', '-)', 'STADIUMEND', 'SUBROUTINEEND', 'PIPE', 'CYLINDEREND', 'DIAMOND_STOP', 'TAGEND', 'TRAPEND', 'INVTRAPEND', 'UNICODE_TEXT', 'TEXT', 'TAGSTART', got 'PS'</code><button class="copy-code-button"><svg xmlns="http://www.w3.org/2000/svg" width="24" height="24" viewBox="0 0 24 24" fill="none" stroke="currentColor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round" class="svg-icon lucide-copy"><rect x="8" y="8" width="14" height="14" rx="2" ry="2"></rect><path d="M4 16c-1.1 0-2-.9-2-2V4c0-1.1.9-2 2-2h10c1.1 0 2 .9 2 2"></path></svg></button></pre></div><div class="el-p"><p dir="auto">Aqui, os documentos processados alimentam tanto o índice vetorial (para busca semântica) quanto opcionalmente um índice BM25 (busca exata). Em runtime, a consulta do usuário dispara ambos os mecanismos e reagrupa resultados.</p></div><div class="el-h2"><h2 data-heading="6. Mecanismos de Busca e Recuperação" dir="auto" class="heading" id="6._Mecanismos_de_Busca_e_Recuperação_0"><span class="heading-collapse-indicator collapse-indicator collapse-icon"><svg xmlns="http://www.w3.org/2000/svg" width="24" height="24" viewBox="0 0 24 24" fill="none" stroke="currentColor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round" class="svg-icon right-triangle"><path d="M3 8L12 17L21 8"></path></svg></span>6. Mecanismos de Busca e Recuperação</h2></div><div class="el-ul"><ul class="has-list-bullet">
<li data-line="0" dir="auto"><span class="list-bullet"></span><strong>BM25 (Busca por palavras-chave):</strong> Algoritmo clássico de IR (ex.: Apache Lucene, Whoosh). Rápido para termo exato【29†L77-L85】, mas não captura sinônimos. Use para complementar a busca vetorial.  </li>
<li data-line="1" dir="auto"><span class="list-bullet"></span><strong>Vetorial (embeddings):</strong> Utiliza distância (cosseno) entre embeddings para semântica【29†L99-L107】. Indexado em FAISS, Milvus, Chroma, etc. FAISS é uma <em>biblioteca</em> de pesquisa vetorial muito rápida【27†L99-L108】 (ideal para protótipos), mas exige que você gerencie armazenamento. Milvus é um banco vetorial completo, escalável e otimizado (C++/GPU)【27†L72-L81】, adequado para grandes volumes. Chroma é leve, fácil de usar direto em Python/Notebook, ideal para aplicações LLMs locais【27†L163-L172】. Veja comparativo:</li>
</ul></div><div class="el-table" dir="ltr" style="overflow-x: auto;"><table>
<thead>
<tr>
<th dir="ltr">Banco Vetorial</th>
<th dir="ltr">Escalabilidade</th>
<th dir="ltr">Complexidade de setup</th>
<th dir="ltr">Casos de Uso</th>
</tr>
</thead>
<tbody>
<tr>
<td dir="ltr"><strong>Milvus</strong></td>
<td dir="ltr">Muito alta (milhões de vetores)【27†L72-L81】</td>
<td dir="ltr">Médio (Docker/clusters)</td>
<td dir="ltr">Sistemas de produção robustos, multiusuário, com SSD/GPU【27†L72-L81】</td>
</tr>
<tr>
<td dir="ltr"><strong>FAISS</strong></td>
<td dir="ltr">Alta (libs CPU/GPU)【27†L99-L108】</td>
<td dir="ltr">Baixa (apenas biblioteca)</td>
<td dir="ltr">Pesquisa rápida e customizável, P&amp;D, protótipos【27†L99-L108】</td>
</tr>
<tr>
<td dir="ltr"><strong>Chroma</strong></td>
<td dir="ltr">Moderada (para centenas de mil)【27†L163-L172】</td>
<td dir="ltr">Muito baixa (pip install)</td>
<td dir="ltr">Prototipagem e RAG local, integração com LangChain/LlamaIndex【27†L163-L172】</td>
</tr>
<tr>
<td dir="ltr"><strong>Qdrant</strong></td>
<td dir="ltr">Alta (Rust-based)【27†L131-L140】</td>
<td dir="ltr">Baixa-média (docker)</td>
<td dir="ltr">Busca híbrida com filtros, multitenancy, produção segura</td>
</tr>
<tr>
<td dir="ltr"><strong>Outros</strong></td>
<td dir="ltr">e.g. Weaviate, Pinecone (cloud)</td>
<td dir="ltr">variável</td>
<td dir="auto"></td>
</tr>
</tbody>
</table></div><div class="el-blockquote"><blockquote dir="auto">
<p><em>Dica:</em> <em>Hybrid Search</em> combina BM25 + vetorial, usando fusão de rankings【29†L112-L121】. Por exemplo, obtenha top‑K resultados de cada método e re-ranking com ponderação:  </p>
<pre class="language-python"><code data-line="1" class="language-python is-loaded">final_score <span class="token operator">=</span> α <span class="token operator">*</span> BM25_score <span class="token operator">+</span> <span class="token punctuation">(</span><span class="token number">1</span><span class="token operator">-</span>α<span class="token punctuation">)</span> <span class="token operator">*</span> Vector_score
</code><button class="copy-code-button"><svg xmlns="http://www.w3.org/2000/svg" width="24" height="24" viewBox="0 0 24 24" fill="none" stroke="currentColor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round" class="svg-icon lucide-copy"><rect x="8" y="8" width="14" height="14" rx="2" ry="2"></rect><path d="M4 16c-1.1 0-2-.9-2-2V4c0-1.1.9-2 2-2h10c1.1 0 2 .9 2 2"></path></svg></button></pre>
<p>Isso atinge tanto precisão exata quanto similaridade semântica【29†L112-L121】.</p>
</blockquote></div><div class="el-h2"><h2 data-heading="7. Arquitetura do Agente Conversacional" dir="auto" class="heading" id="7._Arquitetura_do_Agente_Conversacional_0"><span class="heading-collapse-indicator collapse-indicator collapse-icon"><svg xmlns="http://www.w3.org/2000/svg" width="24" height="24" viewBox="0 0 24 24" fill="none" stroke="currentColor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round" class="svg-icon right-triangle"><path d="M3 8L12 17L21 8"></path></svg></span>7. Arquitetura do Agente Conversacional</h2></div><div class="el-p"><p dir="auto">Um agente local típico integra:</p></div><div class="el-ol"><ol>
<li data-line="0" dir="auto"><strong>Interface de usuário:</strong> CLI, web ou chat UI local (pode ser simples HTML/JS ou terminal). Recebe perguntas e exibe respostas.  </li>
<li data-line="1" dir="auto"><strong>Orquestrador (Agente):</strong> Coordena o pipeline. Em frameworks (LangChain, LlamaIndex etc.), define ferramentas para busca de contexto e geração da resposta. Pode implementar multi-turnos e manter <em>memória</em> do diálogo.  </li>
<li data-line="2" dir="auto"><strong>Mecanismo RAG:</strong> Dado o prompt do usuário, primeiro recupera documentos relevantes do índice (vetorial + BM25). Após recuperar e concatenar contexto, formata um prompt para o LLM.  </li>
<li data-line="3" dir="auto"><strong>LLM local (Ollama):</strong> Gera a resposta baseada no prompt augmentado. Pode usar funções de <em>system/user</em> messages para guiar o comportamento.  </li>
<li data-line="4" dir="auto"><strong>Gestão de contexto:</strong> Guarda histórico das conversas recentes. Este <em>memory stack</em> pode ser re-indexado para referência futura ou usado via embeddings de histórico.  </li>
</ol></div><div class="el-p"><p dir="auto">Como exemplo de fluxo:</p></div><div class="el-pre"><div class="mermaid"><svg aria-roledescription="flowchart-v2" role="graphics-document document" viewBox="0 0 1337.40625 373" height="373" class="flowchart" xmlns:xlink="http://www.w3.org/1999/xlink" xmlns="http://www.w3.org/2000/svg" width="1337.40625" id="m68a75d1f1c1c77d6"><style>#m68a75d1f1c1c77d6{font-family:var(--font-mermaid);font-size:16px;fill:#333;}#m68a75d1f1c1c77d6 .error-icon{fill:#552222;}#m68a75d1f1c1c77d6 .error-text{fill:#552222;stroke:#552222;}#m68a75d1f1c1c77d6 .edge-thickness-normal{stroke-width:1px;}#m68a75d1f1c1c77d6 .edge-thickness-thick{stroke-width:3.5px;}#m68a75d1f1c1c77d6 .edge-pattern-solid{stroke-dasharray:0;}#m68a75d1f1c1c77d6 .edge-thickness-invisible{stroke-width:0;fill:none;}#m68a75d1f1c1c77d6 .edge-pattern-dashed{stroke-dasharray:3;}#m68a75d1f1c1c77d6 .edge-pattern-dotted{stroke-dasharray:2;}#m68a75d1f1c1c77d6 .marker{fill:#333333;stroke:#333333;}#m68a75d1f1c1c77d6 .marker.cross{stroke:#333333;}#m68a75d1f1c1c77d6 svg{font-family:var(--font-mermaid);font-size:16px;}#m68a75d1f1c1c77d6 p{margin:0;}#m68a75d1f1c1c77d6 .label{font-family:var(--font-mermaid);color:#333;}#m68a75d1f1c1c77d6 .cluster-label text{fill:#333;}#m68a75d1f1c1c77d6 .cluster-label span{color:#333;}#m68a75d1f1c1c77d6 .cluster-label span p{background-color:transparent;}#m68a75d1f1c1c77d6 .label text,#m68a75d1f1c1c77d6 span{fill:#333;color:#333;}#m68a75d1f1c1c77d6 .node rect,#m68a75d1f1c1c77d6 .node circle,#m68a75d1f1c1c77d6 .node ellipse,#m68a75d1f1c1c77d6 .node polygon,#m68a75d1f1c1c77d6 .node path{fill:#ECECFF;stroke:#9370DB;stroke-width:1px;}#m68a75d1f1c1c77d6 .rough-node .label text,#m68a75d1f1c1c77d6 .node .label text,#m68a75d1f1c1c77d6 .image-shape .label,#m68a75d1f1c1c77d6 .icon-shape .label{text-anchor:middle;}#m68a75d1f1c1c77d6 .node .katex path{fill:#000;stroke:#000;stroke-width:1px;}#m68a75d1f1c1c77d6 .rough-node .label,#m68a75d1f1c1c77d6 .node .label,#m68a75d1f1c1c77d6 .image-shape .label,#m68a75d1f1c1c77d6 .icon-shape .label{text-align:center;}#m68a75d1f1c1c77d6 .node.clickable{cursor:pointer;}#m68a75d1f1c1c77d6 .root .anchor path{fill:#333333!important;stroke-width:0;stroke:#333333;}#m68a75d1f1c1c77d6 .arrowheadPath{fill:#333333;}#m68a75d1f1c1c77d6 .edgePath .path{stroke:#333333;stroke-width:2.0px;}#m68a75d1f1c1c77d6 .flowchart-link{stroke:#333333;fill:none;}#m68a75d1f1c1c77d6 .edgeLabel{background-color:rgba(232,232,232, 0.8);text-align:center;}#m68a75d1f1c1c77d6 .edgeLabel p{background-color:rgba(232,232,232, 0.8);}#m68a75d1f1c1c77d6 .edgeLabel rect{opacity:0.5;background-color:rgba(232,232,232, 0.8);fill:rgba(232,232,232, 0.8);}#m68a75d1f1c1c77d6 .labelBkg{background-color:rgba(232, 232, 232, 0.5);}#m68a75d1f1c1c77d6 .cluster rect{fill:#ffffde;stroke:#aaaa33;stroke-width:1px;}#m68a75d1f1c1c77d6 .cluster text{fill:#333;}#m68a75d1f1c1c77d6 .cluster span{color:#333;}#m68a75d1f1c1c77d6 div.mermaidTooltip{position:absolute;text-align:center;max-width:200px;padding:2px;font-family:var(--font-mermaid);font-size:12px;background:hsl(80, 100%, 96.2745098039%);border:1px solid #aaaa33;border-radius:2px;pointer-events:none;z-index:100;}#m68a75d1f1c1c77d6 .flowchartTitleText{text-anchor:middle;font-size:18px;fill:#333;}#m68a75d1f1c1c77d6 rect.text{fill:none;stroke-width:0;}#m68a75d1f1c1c77d6 .icon-shape,#m68a75d1f1c1c77d6 .image-shape{background-color:rgba(232,232,232, 0.8);text-align:center;}#m68a75d1f1c1c77d6 .icon-shape p,#m68a75d1f1c1c77d6 .image-shape p{background-color:rgba(232,232,232, 0.8);padding:2px;}#m68a75d1f1c1c77d6 .icon-shape rect,#m68a75d1f1c1c77d6 .image-shape rect{opacity:0.5;background-color:rgba(232,232,232, 0.8);fill:rgba(232,232,232, 0.8);}#m68a75d1f1c1c77d6 :root{--mermaid-font-family:"trebuchet ms",verdana,arial,sans-serif;}</style><g><marker orient="auto" markerHeight="8" markerWidth="8" markerUnits="userSpaceOnUse" refY="5" refX="5" viewBox="0 0 10 10" class="marker flowchart-v2" id="m68a75d1f1c1c77d6-m68a75d1f1c1c77d6_flowchart-v2-pointEnd"><path style="stroke-width: 1; stroke-dasharray: 1, 0;" class="arrowMarkerPath" d="M 0 0 L 10 5 L 0 10 z"></path></marker><marker orient="auto" markerHeight="8" markerWidth="8" markerUnits="userSpaceOnUse" refY="5" refX="4.5" viewBox="0 0 10 10" class="marker flowchart-v2" id="m68a75d1f1c1c77d6-m68a75d1f1c1c77d6_flowchart-v2-pointStart"><path style="stroke-width: 1; stroke-dasharray: 1, 0;" class="arrowMarkerPath" d="M 0 5 L 10 10 L 10 0 z"></path></marker><marker orient="auto" markerHeight="11" markerWidth="11" markerUnits="userSpaceOnUse" refY="5" refX="11" viewBox="0 0 10 10" class="marker flowchart-v2" id="m68a75d1f1c1c77d6-m68a75d1f1c1c77d6_flowchart-v2-circleEnd"><circle style="stroke-width: 1; stroke-dasharray: 1, 0;" class="arrowMarkerPath" r="5" cy="5" cx="5"></circle></marker><marker orient="auto" markerHeight="11" markerWidth="11" markerUnits="userSpaceOnUse" refY="5" refX="-1" viewBox="0 0 10 10" class="marker flowchart-v2" id="m68a75d1f1c1c77d6-m68a75d1f1c1c77d6_flowchart-v2-circleStart"><circle style="stroke-width: 1; stroke-dasharray: 1, 0;" class="arrowMarkerPath" r="5" cy="5" cx="5"></circle></marker><marker orient="auto" markerHeight="11" markerWidth="11" markerUnits="userSpaceOnUse" refY="5.2" refX="12" viewBox="0 0 11 11" class="marker cross flowchart-v2" id="m68a75d1f1c1c77d6-m68a75d1f1c1c77d6_flowchart-v2-crossEnd"><path style="stroke-width: 2; stroke-dasharray: 1, 0;" class="arrowMarkerPath" d="M 1,1 l 9,9 M 10,1 l -9,9"></path></marker><marker orient="auto" markerHeight="11" markerWidth="11" markerUnits="userSpaceOnUse" refY="5.2" refX="-1" viewBox="0 0 11 11" class="marker cross flowchart-v2" id="m68a75d1f1c1c77d6-m68a75d1f1c1c77d6_flowchart-v2-crossStart"><path style="stroke-width: 2; stroke-dasharray: 1, 0;" class="arrowMarkerPath" d="M 1,1 l 9,9 M 10,1 l -9,9"></path></marker><g class="root"><g class="clusters"><g data-look="classic" id="Processamento" class="cluster"><rect height="357" width="657.1875" y="8" x="672.21875" style="fill:#f9f !important;stroke:#333 !important;stroke-width:1px !important"></rect><g transform="translate(941.8125, 8)" class="cluster-label"><foreignObject height="24" width="118"><div style="display: table-cell; white-space: nowrap; line-height: 1.5; max-width: 200px; text-align: center;" xmlns="http://www.w3.org/1999/xhtml"><span class="nodeLabel"><p>Processamento</p></span></div></foreignObject></g></g><g data-look="classic" id="subGraph0" class="cluster"><rect height="136" width="479.890625" y="104" x="8" style=""></rect><g transform="translate(174.8515625, 104)" class="cluster-label"><foreignObject height="24" width="146.1875"><div style="display: table-cell; white-space: nowrap; line-height: 1.5; max-width: 200px; text-align: center;" xmlns="http://www.w3.org/1999/xhtml"><span class="nodeLabel"><p>Usuário &amp; Interface</p></span></div></foreignObject></g></g></g><g class="edgePaths"><path marker-end="url(#m68a75d1f1c1c77d6-m68a75d1f1c1c77d6_flowchart-v2-pointEnd)" style="" class="edge-thickness-normal edge-pattern-solid edge-thickness-normal edge-pattern-solid flowchart-link" id="L_U_UI_0" d="M152.141,177L162.035,177C171.93,177,191.719,177,210.841,177C229.964,177,248.419,177,257.647,177L266.875,177"></path><path marker-end="url(#m68a75d1f1c1c77d6-m68a75d1f1c1c77d6_flowchart-v2-pointEnd)" style="" class="edge-thickness-normal edge-pattern-solid edge-thickness-normal edge-pattern-solid flowchart-link" id="L_UI_Agent_1" d="M462.891,159.545L467.057,158.788C471.224,158.03,479.557,156.515,499.085,155.758C518.612,155,549.333,155,580.055,155C610.776,155,641.497,155,660.381,155.945C679.264,156.89,686.31,158.781,689.833,159.726L693.355,160.671"></path><path marker-end="url(#m68a75d1f1c1c77d6-m68a75d1f1c1c77d6_flowchart-v2-pointEnd)" style="" class="edge-thickness-normal edge-pattern-solid edge-thickness-normal edge-pattern-solid flowchart-link" id="L_Agent_Search_2" d="M794.624,150L816.822,135.167C839.02,120.333,883.416,90.667,924.383,77.508C965.349,64.349,1002.886,67.698,1021.654,69.372L1040.422,71.047"></path><path marker-end="url(#m68a75d1f1c1c77d6-m68a75d1f1c1c77d6_flowchart-v2-pointEnd)" style="" class="edge-thickness-normal edge-pattern-solid edge-thickness-normal edge-pattern-solid flowchart-link" id="L_Search_Agent_3" d="M1044.406,101.979L1024.974,104.815C1005.542,107.652,966.677,113.326,928.445,122.444C890.213,131.563,852.613,144.125,833.813,150.407L815.013,156.688"></path><path marker-end="url(#m68a75d1f1c1c77d6-m68a75d1f1c1c77d6_flowchart-v2-pointEnd)" style="" class="edge-thickness-normal edge-pattern-solid edge-thickness-normal edge-pattern-solid flowchart-link" id="L_Agent_OllamaOllama_4" d="M811.219,177L830.651,177C850.083,177,888.948,177,933.587,179.249C978.227,181.498,1028.641,185.995,1053.848,188.244L1079.055,190.493"></path><path marker-end="url(#m68a75d1f1c1c77d6-m68a75d1f1c1c77d6_flowchart-v2-pointEnd)" style="" class="edge-thickness-normal edge-pattern-solid edge-thickness-normal edge-pattern-solid flowchart-link" id="L_OllamaOllama_Agent_5" d="M1083.039,210.116L1057.168,213.263C1031.297,216.41,979.555,222.705,934.89,220.223C890.225,217.741,852.638,206.481,833.844,200.852L815.051,195.222"></path><path marker-end="url(#m68a75d1f1c1c77d6-m68a75d1f1c1c77d6_flowchart-v2-pointEnd)" style="" class="edge-thickness-normal edge-pattern-solid edge-thickness-normal edge-pattern-solid flowchart-link" id="L_Agent_UI_6" d="M697.219,192.293L693.052,193.411C688.885,194.528,680.552,196.764,661.025,197.882C641.497,199,610.776,199,580.055,199C549.333,199,518.612,199,499.741,198.362C480.869,197.723,473.848,196.447,470.337,195.809L466.826,195.17"></path><path marker-end="url(#m68a75d1f1c1c77d6-m68a75d1f1c1c77d6_flowchart-v2-pointEnd)" style="" class="edge-thickness-normal edge-pattern-solid edge-thickness-normal edge-pattern-solid flowchart-link" id="L_Agent_Memory_7" d="M791.417,204L814.15,220.5C836.882,237,882.347,270,928.575,286.5C974.802,303,1021.792,303,1045.286,303L1068.781,303"></path></g><g class="edgeLabels"><g transform="translate(211.5078125, 177)" class="edgeLabel"><g transform="translate(-34.3671875, -12)" class="label"><foreignObject height="24" width="68.734375"><div style="display: table-cell; white-space: nowrap; line-height: 1.5; max-width: 200px; text-align: center;" class="labelBkg" xmlns="http://www.w3.org/1999/xhtml"><span class="edgeLabel"><p>Pergunta</p></span></div></foreignObject></g></g><g transform="translate(580.0546875, 155)" class="edgeLabel"><g transform="translate(-55.9765625, -12)" class="label"><foreignObject height="24" width="111.953125"><div style="display: table-cell; white-space: nowrap; line-height: 1.5; max-width: 200px; text-align: center;" class="labelBkg" xmlns="http://www.w3.org/1999/xhtml"><span class="edgeLabel"><p>Pega Pergunta</p></span></div></foreignObject></g></g><g transform="translate(927.8125, 61)" class="edgeLabel"><g transform="translate(-42.1875, -12)" class="label"><foreignObject height="24" width="84.375"><div style="display: table-cell; white-space: nowrap; line-height: 1.5; max-width: 200px; text-align: center;" class="labelBkg" xmlns="http://www.w3.org/1999/xhtml"><span class="edgeLabel"><p>Busca RAG</p></span></div></foreignObject></g></g><g transform="translate(927.8125, 119)" class="edgeLabel"><g transform="translate(-91.59375, -12)" class="label"><foreignObject height="24" width="183.1875"><div style="display: table-cell; white-space: nowrap; line-height: 1.5; max-width: 200px; text-align: center;" class="labelBkg" xmlns="http://www.w3.org/1999/xhtml"><span class="edgeLabel"><p>Documentos Relevantes</p></span></div></foreignObject></g></g><g transform="translate(927.8125, 177)" class="edgeLabel"><g transform="translate(-45.765625, -12)" class="label"><foreignObject height="24" width="91.53125"><div style="display: table-cell; white-space: nowrap; line-height: 1.5; max-width: 200px; text-align: center;" class="labelBkg" xmlns="http://www.w3.org/1999/xhtml"><span class="edgeLabel"><p>Chama LLM</p></span></div></foreignObject></g></g><g transform="translate(927.8125, 229)" class="edgeLabel"><g transform="translate(-65.53125, -12)" class="label"><foreignObject height="24" width="131.0625"><div style="display: table-cell; white-space: nowrap; line-height: 1.5; max-width: 200px; text-align: center;" class="labelBkg" xmlns="http://www.w3.org/1999/xhtml"><span class="edgeLabel"><p>Resposta Gerada</p></span></div></foreignObject></g></g><g transform="translate(580.0546875, 199)" class="edgeLabel"><g transform="translate(-67.1640625, -12)" class="label"><foreignObject height="24" width="134.328125"><div style="display: table-cell; white-space: nowrap; line-height: 1.5; max-width: 200px; text-align: center;" class="labelBkg" xmlns="http://www.w3.org/1999/xhtml"><span class="edgeLabel"><p>Retorna Resposta</p></span></div></foreignObject></g></g><g transform="translate(927.8125, 303)" class="edgeLabel"><g transform="translate(-66.71875, -12)" class="label"><foreignObject height="24" width="133.4375"><div style="display: table-cell; white-space: nowrap; line-height: 1.5; max-width: 200px; text-align: center;" class="labelBkg" xmlns="http://www.w3.org/1999/xhtml"><span class="edgeLabel"><p>Atualiza Memória</p></span></div></foreignObject></g></g></g><g class="nodes"><g transform="translate(92.5703125, 177)" id="flowchart-U-5" class="node default"><rect height="54" width="119.140625" y="-27" x="-59.5703125" style="" class="basic label-container"></rect><g transform="translate(-29.5703125, -12)" style="" class="label"><rect></rect><foreignObject height="24" width="59.140625"><div style="display: table-cell; white-space: nowrap; line-height: 1.5; max-width: 200px; text-align: center;" xmlns="http://www.w3.org/1999/xhtml"><span class="nodeLabel"><p>Usuário</p></span></div></foreignObject></g></g><g transform="translate(366.8828125, 177)" id="flowchart-UI-6" class="node default"><rect height="54" width="192.015625" y="-27" x="-96.0078125" style="" class="basic label-container"></rect><g transform="translate(-66.0078125, -12)" style="" class="label"><rect></rect><foreignObject height="24" width="132.015625"><div style="display: table-cell; white-space: nowrap; line-height: 1.5; max-width: 200px; text-align: center;" xmlns="http://www.w3.org/1999/xhtml"><span class="nodeLabel"><p>Interface de Chat</p></span></div></foreignObject></g></g><g transform="translate(754.21875, 177)" id="flowchart-Agent-8" class="node default"><rect height="54" width="114" y="-27" x="-57" style="" class="basic label-container"></rect><g transform="translate(-27, -12)" style="" class="label"><rect></rect><foreignObject height="24" width="54"><div style="display: table-cell; white-space: nowrap; line-height: 1.5; max-width: 200px; text-align: center;" xmlns="http://www.w3.org/1999/xhtml"><span class="nodeLabel"><p>Agente</p></span></div></foreignObject></g></g><g transform="translate(1174.40625, 83)" id="flowchart-Search-10" class="node default"><rect height="78" width="260" y="-39" x="-130" style="" class="basic label-container"></rect><g transform="translate(-100, -24)" style="" class="label"><rect></rect><foreignObject height="48" width="200"><div style="display: table; white-space: break-spaces; line-height: 1.5; max-width: 200px; text-align: center; width: 200px;" xmlns="http://www.w3.org/1999/xhtml"><span class="nodeLabel"><p>Banco de Busca Vetorial/Texto</p></span></div></foreignObject></g></g><g transform="translate(1174.40625, 199)" id="flowchart-OllamaOllama-14" class="node default"><rect height="54" width="182.734375" y="-27" x="-91.3671875" style="" class="basic label-container"></rect><g transform="translate(-61.3671875, -12)" style="" class="label"><rect></rect><foreignObject height="24" width="122.734375"><div style="display: table-cell; white-space: nowrap; line-height: 1.5; max-width: 200px; text-align: center;" xmlns="http://www.w3.org/1999/xhtml"><span class="nodeLabel"><p>Servidor Ollama</p></span></div></foreignObject></g></g><g transform="translate(1174.40625, 303)" id="flowchart-Memory-20" class="node default"><rect height="54" width="203.25" y="-27" x="-101.625" style="" class="basic label-container"></rect><g transform="translate(-71.625, -12)" style="" class="label"><rect></rect><foreignObject height="24" width="143.25"><div style="display: table-cell; white-space: nowrap; line-height: 1.5; max-width: 200px; text-align: center;" xmlns="http://www.w3.org/1999/xhtml"><span class="nodeLabel"><p>Banco de Memória</p></span></div></foreignObject></g></g></g></g></g></svg></div></div><div class="el-p"><p dir="auto">Neste diagrama, o agente recebe a pergunta, recupera contexto relevante (<code>Search</code>), então invoca o modelo via API Ollama para gerar a resposta. Simultaneamente, atualiza seu histórico (<em>Memory</em>), garantindo contexto para futuras interações. Ferramentas de orquestração (LangChain Agent, AutoGen, etc.) podem implementar fluxos complexos como chamadas de ferramentas externas, repetição de RAG em vários estágios ou feedback do usuário para refinar a resposta.</p></div><div class="el-p"><p dir="auto"><strong>Segurança e Privacidade:</strong> Como tudo roda localmente, os dados privados (Markdown, histórico) permanecem no dispositivo, reduzindo riscos de vazamento. No entanto, esteja atento a:  </p></div><div class="el-ul"><ul class="has-list-bullet">
<li data-line="0" dir="auto"><span class="list-bullet"></span>Licenciamento dos modelos (respeitar termos de uso).  </li>
<li data-line="1" dir="auto"><span class="list-bullet"></span>Sanitização de entrada (não executar código malicioso).  </li>
<li data-line="2" dir="auto"><span class="list-bullet"></span>Controle de acesso (especialmente se expor API localmente).  </li>
</ul></div><div class="el-h2"><h2 data-heading="8. Exemplos de Código e Comandos" dir="auto" class="heading" id="8._Exemplos_de_Código_e_Comandos_0"><span class="heading-collapse-indicator collapse-indicator collapse-icon"><svg xmlns="http://www.w3.org/2000/svg" width="24" height="24" viewBox="0 0 24 24" fill="none" stroke="currentColor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round" class="svg-icon right-triangle"><path d="M3 8L12 17L21 8"></path></svg></span>8. Exemplos de Código e Comandos</h2></div><div class="el-ul"><ul class="has-list-bullet">
<li data-line="0" dir="auto"><span class="list-bullet"></span>
<p><strong>Instalação (Linux):</strong>  </p>
<pre class="language-bash"><code data-line="1" class="language-bash is-loaded"><span class="token function">curl</span> <span class="token parameter variable">-fsSL</span> https://ollama.com/install.sh <span class="token operator">|</span> <span class="token function">sh</span>   <span class="token comment"># Instalação rápida【15†L93-L98】</span>
ollama serve                                   <span class="token comment"># Inicia servidor no 127.0.0.1:11434【15†L113-L117】</span>
</code><button class="copy-code-button"><svg xmlns="http://www.w3.org/2000/svg" width="24" height="24" viewBox="0 0 24 24" fill="none" stroke="currentColor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round" class="svg-icon lucide-copy"><rect x="8" y="8" width="14" height="14" rx="2" ry="2"></rect><path d="M4 16c-1.1 0-2-.9-2-2V4c0-1.1.9-2 2-2h10c1.1 0 2 .9 2 2"></path></svg></button></pre>
</li>
<li data-line="6" dir="auto"><span class="list-bullet"></span>
<p><strong>Instalação (Windows):</strong> Baixe o instalador do <a data-tooltip-position="top" aria-label="https://ollama.com/download" rel="noopener nofollow" class="external-link is-unresolved" href="https://ollama.com/download" target="_self">site oficial</a> e siga as instruções. Depois, abra <code>powershell</code> e ajuste PATH se necessário.  </p>
</li>
<li data-line="7" dir="auto"><span class="list-bullet"></span>
<p><strong>Exibir versão:</strong>  </p>
<pre class="language-bash"><code data-line="8" class="language-bash is-loaded">ollama <span class="token parameter variable">-v</span>
</code><button class="copy-code-button"><svg xmlns="http://www.w3.org/2000/svg" width="24" height="24" viewBox="0 0 24 24" fill="none" stroke="currentColor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round" class="svg-icon lucide-copy"><rect x="8" y="8" width="14" height="14" rx="2" ry="2"></rect><path d="M4 16c-1.1 0-2-.9-2-2V4c0-1.1.9-2 2-2h10c1.1 0 2 .9 2 2"></path></svg></button></pre>
</li>
<li data-line="12" dir="auto"><span class="list-bullet"></span>
<p><strong>Listar e carregar modelos:</strong>  </p>
<pre class="language-bash"><code data-line="13" class="language-bash is-loaded">ollama list                <span class="token comment"># modelos locais disponíveis</span>
ollama run llama3.2        <span class="token comment"># baixa e inicia Llama3.2 (3B)【42†L169-L174】</span>
ollama pull gemma2:27b     <span class="token comment"># baixa Gemma2 27B sem iniciar【42†L179-L183】</span>
</code><button class="copy-code-button"><svg xmlns="http://www.w3.org/2000/svg" width="24" height="24" viewBox="0 0 24 24" fill="none" stroke="currentColor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round" class="svg-icon lucide-copy"><rect x="8" y="8" width="14" height="14" rx="2" ry="2"></rect><path d="M4 16c-1.1 0-2-.9-2-2V4c0-1.1.9-2 2-2h10c1.1 0 2 .9 2 2"></path></svg></button></pre>
</li>
<li data-line="19" dir="auto"><span class="list-bullet"></span>
<p><strong>Exemplo de API RAG:</strong> Com um serviço (ex.: FastAPI) ou CLI, consulte o agente. Por simplicidade, use <code>curl</code>:  </p>
<pre class="language-bash"><code data-line="20" class="language-bash is-loaded"><span class="token function">curl</span> http://localhost:11434/api/chat <span class="token parameter variable">-d</span> <span class="token string">'{
  "model": "gemma3", 
  "messages": [{"role": "user", "content": "Como instalo Ollama no Linux?"}]
}'</span>
</code><button class="copy-code-button"><svg xmlns="http://www.w3.org/2000/svg" width="24" height="24" viewBox="0 0 24 24" fill="none" stroke="currentColor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round" class="svg-icon lucide-copy"><rect x="8" y="8" width="14" height="14" rx="2" ry="2"></rect><path d="M4 16c-1.1 0-2-.9-2-2V4c0-1.1.9-2 2-2h10c1.1 0 2 .9 2 2"></path></svg></button></pre>
<p>Isso retorna uma resposta JSON gerada pelo modelo <strong>Gemma&nbsp;3</strong>【48†L137-L140】.  </p>
</li>
<li data-line="28" dir="auto"><span class="list-bullet"></span>
<p><strong>Gerar embeddings:</strong>  </p>
<pre class="language-bash"><code data-line="29" class="language-bash is-loaded"><span class="token function">curl</span> <span class="token parameter variable">-X</span> POST http://localhost:11434/api/embed <span class="token punctuation">\</span>
  <span class="token parameter variable">-H</span> <span class="token string">"Content-Type: application/json"</span> <span class="token punctuation">\</span>
  <span class="token parameter variable">-d</span> <span class="token string">'{"model": "embeddinggemma", "input": "Exemplo de texto para embed."}'</span>
</code><button class="copy-code-button"><svg xmlns="http://www.w3.org/2000/svg" width="24" height="24" viewBox="0 0 24 24" fill="none" stroke="currentColor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round" class="svg-icon lucide-copy"><rect x="8" y="8" width="14" height="14" rx="2" ry="2"></rect><path d="M4 16c-1.1 0-2-.9-2-2V4c0-1.1.9-2 2-2h10c1.1 0 2 .9 2 2"></path></svg></button></pre>
</li>
<li data-line="35" dir="auto"><span class="list-bullet"></span>
<p><strong>Indexação (exemplo em Python):</strong> Usando <code>ollama-python</code> e FAISS:  </p>
<pre class="language-python"><code data-line="36" class="language-python is-loaded"><span class="token keyword">from</span> ollama <span class="token keyword">import</span> embed
<span class="token keyword">from</span> faiss <span class="token keyword">import</span> IndexFlatIP
<span class="token keyword">import</span> numpy <span class="token keyword">as</span> np

<span class="token comment"># Carrega/embebe textos e insere no índice FAISS</span>
index <span class="token operator">=</span> IndexFlatIP<span class="token punctuation">(</span><span class="token number">1536</span><span class="token punctuation">)</span>   <span class="token comment"># supondo dimensão 1536</span>
<span class="token keyword">for</span> doc <span class="token keyword">in</span> documentos<span class="token punctuation">:</span>
    vec <span class="token operator">=</span> np<span class="token punctuation">.</span>array<span class="token punctuation">(</span>embed<span class="token punctuation">(</span>model<span class="token operator">=</span><span class="token string">'embeddinggemma'</span><span class="token punctuation">,</span> <span class="token builtin">input</span><span class="token operator">=</span>doc<span class="token punctuation">[</span><span class="token string">'texto'</span><span class="token punctuation">]</span><span class="token punctuation">)</span><span class="token punctuation">[</span><span class="token string">'embeddings'</span><span class="token punctuation">]</span><span class="token punctuation">[</span><span class="token number">0</span><span class="token punctuation">]</span><span class="token punctuation">,</span> dtype<span class="token operator">=</span><span class="token string">'float32'</span><span class="token punctuation">)</span>
    index<span class="token punctuation">.</span>add<span class="token punctuation">(</span>vec<span class="token punctuation">.</span>reshape<span class="token punctuation">(</span><span class="token number">1</span><span class="token punctuation">,</span> <span class="token operator">-</span><span class="token number">1</span><span class="token punctuation">)</span><span class="token punctuation">)</span>
</code><button class="copy-code-button"><svg xmlns="http://www.w3.org/2000/svg" width="24" height="24" viewBox="0 0 24 24" fill="none" stroke="currentColor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round" class="svg-icon lucide-copy"><rect x="8" y="8" width="14" height="14" rx="2" ry="2"></rect><path d="M4 16c-1.1 0-2-.9-2-2V4c0-1.1.9-2 2-2h10c1.1 0 2 .9 2 2"></path></svg></button></pre>
<p>Para Milvus ou Chroma, use clientes específicos (p. ex. <code>pymilvus</code>, <code>chromadb.Client</code>) e operações <code>insert()</code>.</p>
</li>
<li data-line="49" dir="auto"><span class="list-bullet"></span>
<p><strong>Criação de índice no Milvus (via Docker Compose):</strong>  </p>
<pre class="language-bash"><code data-line="50" class="language-bash is-loaded"><span class="token function">docker-compose</span> down
<span class="token function">wget</span> https://github.com/milvus-io/milvus/releases/latest/download/milvus-standalone-docker-compose.yml <span class="token parameter variable">-O</span> docker-compose.yml
<span class="token function">docker-compose</span> up <span class="token parameter variable">-d</span>
</code><button class="copy-code-button"><svg xmlns="http://www.w3.org/2000/svg" width="24" height="24" viewBox="0 0 24 24" fill="none" stroke="currentColor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round" class="svg-icon lucide-copy"><rect x="8" y="8" width="14" height="14" rx="2" ry="2"></rect><path d="M4 16c-1.1 0-2-.9-2-2V4c0-1.1.9-2 2-2h10c1.1 0 2 .9 2 2"></path></svg></button></pre>
<p>(Exemplo retirado do repositório <a data-tooltip-position="top" aria-label="https://github.com/kevwan/rag-agent" rel="noopener nofollow" class="external-link is-unresolved" href="https://github.com/kevwan/rag-agent" target="_self">RAG agent</a>【40†L431-L438】.)</p>
</li>
</ul></div><div class="el-h2"><h2 data-heading="9. Formatos de Dados e Esquemas" dir="auto" class="heading" id="9._Formatos_de_Dados_e_Esquemas_0"><span class="heading-collapse-indicator collapse-indicator collapse-icon"><svg xmlns="http://www.w3.org/2000/svg" width="24" height="24" viewBox="0 0 24 24" fill="none" stroke="currentColor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round" class="svg-icon right-triangle"><path d="M3 8L12 17L21 8"></path></svg></span>9. Formatos de Dados e Esquemas</h2></div><div class="el-ul"><ul class="has-list-bullet">
<li data-line="0" dir="auto"><span class="list-bullet"></span>
<p><strong>Markdown:</strong> Cada arquivo <code>.md</code> pode conter <em>front-matter</em> (YAML) indicando título, tags, data etc. Exemplo inicial:  </p>
<pre class="language-markdown"><code data-line="1" class="language-markdown is-loaded"><span class="token front-matter-block"><span class="token punctuation">---</span>
<span class="token front-matter yaml language-yaml">title: "Manual de Configuração"
tags: ["setup", "ollama"]
date: 2024-05-20</span>
<span class="token punctuation">---</span></span>

<span class="token title important"><span class="token punctuation">#</span> Instalação  </span>
Para instalar o Ollama, ...
</code><button class="copy-code-button"><svg xmlns="http://www.w3.org/2000/svg" width="24" height="24" viewBox="0 0 24 24" fill="none" stroke="currentColor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round" class="svg-icon lucide-copy"><rect x="8" y="8" width="14" height="14" rx="2" ry="2"></rect><path d="M4 16c-1.1 0-2-.9-2-2V4c0-1.1.9-2 2-2h10c1.1 0 2 .9 2 2"></path></svg></button></pre>
</li>
<li data-line="11" dir="auto"><span class="list-bullet"></span>
<p><strong>Esquemas recomendados:</strong> Armazene cada chunk/documento em JSON com campos como <code>id</code>, <code>title</code>, <code>content</code>, <code>metadata</code> (tags, path). Exemplo:  </p>
<pre class="language-json"><code data-line="12" class="language-json is-loaded"><span class="token punctuation">{</span>
  <span class="token property">"id"</span><span class="token operator">:</span> <span class="token string">"doc1_chunk2"</span><span class="token punctuation">,</span>
  <span class="token property">"title"</span><span class="token operator">:</span> <span class="token string">"Instalação Ollama"</span><span class="token punctuation">,</span>
  <span class="token property">"content"</span><span class="token operator">:</span> <span class="token string">"Execute o comando `curl ...` no terminal."</span><span class="token punctuation">,</span>
  <span class="token property">"metadata"</span><span class="token operator">:</span> <span class="token punctuation">{</span>
    <span class="token property">"source"</span><span class="token operator">:</span> <span class="token string">"docs/instalacao.md"</span><span class="token punctuation">,</span>
    <span class="token property">"tags"</span><span class="token operator">:</span> <span class="token punctuation">[</span><span class="token string">"install"</span><span class="token punctuation">,</span> <span class="token string">"ollama"</span><span class="token punctuation">]</span>
  <span class="token punctuation">}</span>
<span class="token punctuation">}</span>
</code><button class="copy-code-button"><svg xmlns="http://www.w3.org/2000/svg" width="24" height="24" viewBox="0 0 24 24" fill="none" stroke="currentColor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round" class="svg-icon lucide-copy"><rect x="8" y="8" width="14" height="14" rx="2" ry="2"></rect><path d="M4 16c-1.1 0-2-.9-2-2V4c0-1.1.9-2 2-2h10c1.1 0 2 .9 2 2"></path></svg></button></pre>
</li>
<li data-line="23" dir="auto"><span class="list-bullet"></span>
<p><strong>Indexação:</strong> Use sempre o mesmo modelo de embedding para indexar e consultar (vetor dimensão fixa)【40†L364-L372】. Documentos podem ser armazenados em JSON ou em bancos (SQLite, NoSQL) além do vetor DB.  </p>
</li>
</ul></div><div class="el-h2"><h2 data-heading="10. Avaliação e Métricas" dir="auto" class="heading" id="10._Avaliação_e_Métricas_0"><span class="heading-collapse-indicator collapse-indicator collapse-icon"><svg xmlns="http://www.w3.org/2000/svg" width="24" height="24" viewBox="0 0 24 24" fill="none" stroke="currentColor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round" class="svg-icon right-triangle"><path d="M3 8L12 17L21 8"></path></svg></span>10. Avaliação e Métricas</h2></div><div class="el-p"><p dir="auto">Para medir desempenho:  </p></div><div class="el-ul"><ul class="has-list-bullet">
<li data-line="0" dir="auto"><span class="list-bullet"></span><strong>Perplexidade (para modelos)</strong>: avalia quão bem o modelo prediz texto; menor é melhor【33†L53-L61】. Útil em treinamentos.  </li>
<li data-line="1" dir="auto"><span class="list-bullet"></span><strong>Qualidade de geração:</strong> métricas humanas (fluência, coerência) ou LLM-based (compass, Rouge, etc.).  </li>
<li data-line="2" dir="auto"><span class="list-bullet"></span><strong>Precisão de Recuperação:</strong> RAG: métricas de IR como <em>Recall@k</em>, <em>MRR</em> ou <em>nDCG</em> sobre documento relevante.  </li>
<li data-line="3" dir="auto"><span class="list-bullet"></span><strong>Testes de usuário:</strong> avaliações qualitativas com usuários, verificando se respostas estão corretas e úteis.  </li>
</ul></div><div class="el-p"><p dir="auto">Por exemplo, você pode medir a exatidão perguntando questões com respostas conhecidas e verificando se o agente acerta o conteúdo dos Markdown. Ferramentas como <a data-tooltip-position="top" aria-label="https://github.com/CometML/opik" rel="noopener nofollow" class="external-link is-unresolved" href="https://github.com/CometML/opik" target="_self">Opik</a> facilitam computar perplexidade em logs.</p></div><div class="el-h2"><h2 data-heading="11. Boas Práticas de Deploy e Manutenção" dir="auto" class="heading" id="11._Boas_Práticas_de_Deploy_e_Manutenção_0"><span class="heading-collapse-indicator collapse-indicator collapse-icon"><svg xmlns="http://www.w3.org/2000/svg" width="24" height="24" viewBox="0 0 24 24" fill="none" stroke="currentColor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round" class="svg-icon right-triangle"><path d="M3 8L12 17L21 8"></path></svg></span>11. Boas Práticas de Deploy e Manutenção</h2></div><div class="el-ul"><ul class="has-list-bullet">
<li data-line="0" dir="auto"><span class="list-bullet"></span><strong>Backup:</strong> Periodicamente copie os arquivos Markdown e índices vetoriais (faiss, Milvus) para evitar perda de dados.  </li>
<li data-line="1" dir="auto"><span class="list-bullet"></span><strong>Atualizações:</strong> Mantenha Ollama e modelos atualizados (<code>curl ...install.sh | sh</code>【11†L435-L438】) e redo modelo se trocado (por exemplo, baixe versão mais nova).  </li>
<li data-line="2" dir="auto"><span class="list-bullet"></span><strong>Logs:</strong> Configure logs de servidor (Ollama gera logs em <code>~/.ollama/logs</code> no Unix e <code>%LOCALAPPDATA%\Ollama</code> no Windows【16†L164-L172】). Monitore erros e uso de memória.  </li>
<li data-line="3" dir="auto"><span class="list-bullet"></span><strong>Monitoramento:</strong> Em produção local, verifique uso de CPU/GPU e resposta. Em caso de consumo alto, considere reduzir tamanho de modelo ou quantidade de chunks retornados.  </li>
</ul></div><div class="el-h2"><h2 data-heading="12. Riscos e Limitações" dir="auto" class="heading" id="12._Riscos_e_Limitações_0"><span class="heading-collapse-indicator collapse-indicator collapse-icon"><svg xmlns="http://www.w3.org/2000/svg" width="24" height="24" viewBox="0 0 24 24" fill="none" stroke="currentColor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round" class="svg-icon right-triangle"><path d="M3 8L12 17L21 8"></path></svg></span>12. Riscos e Limitações</h2></div><div class="el-ul"><ul class="has-list-bullet">
<li data-line="0" dir="auto"><span class="list-bullet"></span><strong>Licenciamento:</strong> Respeite as licenças dos modelos (ex.: alguns não permitem uso comercial). Modelos <em>open weights</em> (Apache&nbsp;2.0) são seguros, mas modelos com licenças restritivas (Llama 3, Gemma) devem ser usados conforme termos【36†L100-L108】.  </li>
<li data-line="1" dir="auto"><span class="list-bullet"></span><strong>Viés e Precisão:</strong> Modelos podem <em>alucinar</em> ou reproduzir vieses presentes no treinamento. Teste cuidadosamente as respostas do agente. Limite perguntas perigosas e valide informação crítica.  </li>
<li data-line="2" dir="auto"><span class="list-bullet"></span><strong>Segurança:</strong> Embora local, mantenha sistema isolado de redes inseguras. Não expor porta API sem controle. Sanitizar inputs para evitar injeção de comandos (caso use execução de comandos).  </li>
<li data-line="3" dir="auto"><span class="list-bullet"></span><strong>Recursos Limitados:</strong> Modelos muito grandes podem travar o sistema. Garanta que hardware seja adequado ao modelo escolhido【11†L482-L485】【42†L174-L183】.  </li>
</ul></div><div class="el-h2"><h2 data-heading="13. Recursos e Leituras Adicionais" dir="auto" class="heading" id="13._Recursos_e_Leituras_Adicionais_0"><span class="heading-collapse-indicator collapse-indicator collapse-icon"><svg xmlns="http://www.w3.org/2000/svg" width="24" height="24" viewBox="0 0 24 24" fill="none" stroke="currentColor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round" class="svg-icon right-triangle"><path d="M3 8L12 17L21 8"></path></svg></span>13. Recursos e Leituras Adicionais</h2></div><div class="el-ul"><ul class="has-list-bullet">
<li data-line="0" dir="auto"><span class="list-bullet"></span>Documentação oficial: <a data-tooltip-position="top" aria-label="https://docs.ollama.com" rel="noopener nofollow" class="external-link is-unresolved" href="https://docs.ollama.com" target="_self">Ollama Docs (Eng)</a> (instalação, CLI, API, embeddings)【11†L435-L438】【15†L93-L98】【38†L89-L97】.  </li>
<li data-line="1" dir="auto"><span class="list-bullet"></span>Repositórios de modelos: <a data-tooltip-position="top" aria-label="https://ollama.com/library" rel="noopener nofollow" class="external-link is-unresolved" href="https://ollama.com/library" target="_self">Ollama Model Library</a> e <a data-tooltip-position="top" aria-label="https://huggingface.co/models" rel="noopener nofollow" class="external-link is-unresolved" href="https://huggingface.co/models" target="_self">HuggingFace</a> (vários modelos compatíveis).  </li>
<li data-line="2" dir="auto"><span class="list-bullet"></span>Exemplos e tutoriais: repositório <a data-tooltip-position="top" aria-label="https://github.com/kevwan/rag-agent" rel="noopener nofollow" class="external-link is-unresolved" href="https://github.com/kevwan/rag-agent" target="_self">Markdown Knowledge RAG</a>【40†L354-L362】, <a data-tooltip-position="top" aria-label="https://ollama.com" rel="noopener nofollow" class="external-link is-unresolved" href="https://ollama.com" target="_self">Ollama Quickstart</a>【11†L435-L438】【42†L169-L177】.  </li>
<li data-line="3" dir="auto"><span class="list-bullet"></span>Artigos e papers: <em>Retrieval-Augmented Generation</em>, <em>LoRA fine-tuning</em>, pesquisa sobre métricas de LLM (por ex., <a data-tooltip-position="top" aria-label="https://www.comet.com/site/blog/perplexity-for-llm-evaluation" rel="noopener nofollow" class="external-link is-unresolved" href="https://www.comet.com/site/blog/perplexity-for-llm-evaluation" target="_self">Comet/perplexity</a>【33†L53-L61】).  </li>
</ul></div><div class="el-h2"><h2 data-heading="14. Suposições Não Especificadas" dir="auto" class="heading" id="14._Suposições_Não_Especificadas_0"><span class="heading-collapse-indicator collapse-indicator collapse-icon"><svg xmlns="http://www.w3.org/2000/svg" width="24" height="24" viewBox="0 0 24 24" fill="none" stroke="currentColor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round" class="svg-icon right-triangle"><path d="M3 8L12 17L21 8"></path></svg></span>14. Suposições Não Especificadas</h2></div><div class="el-ul"><ul class="has-list-bullet">
<li data-line="0" dir="auto"><span class="list-bullet"></span>A base de conhecimento em Markdown está relativamente organizada (ex.: pastas, front-matter padrão).  </li>
<li data-line="1" dir="auto"><span class="list-bullet"></span>O usuário tem privilégios para instalar software (root/sudo no Linux) e conhecimentos básicos de linha de comando.  </li>
<li data-line="2" dir="auto"><span class="list-bullet"></span>Conexão local ou internet disponível inicialmente (para download de Ollama e modelos).  </li>
<li data-line="3" dir="auto"><span class="list-bullet"></span>Espaço em disco suficiente para os modelos escolhidos.  </li>
<li data-line="4" dir="auto"><span class="list-bullet"></span>Decisões pendentes: escolha de modelo (trade-off entre qualidade e recursos), tipo de índice (FAISS vs. Milvus vs. Chroma), estratégia de fine-tuning (ou usar diretamente RAG). O usuário deve selecionar conforme seu cenário.  </li>
</ul></div><div class="el-p"><p dir="auto"><strong>Fontes:</strong> A maior parte das recomendações e instruções acima estão baseadas na documentação oficial do Ollama【11†L435-L438】【38†L89-L97】, em tutoriais da comunidade【40†L354-L362】【44†L214-L219】 e em comparativos de técnicas de RAG e busca【27†L99-L108】【29†L112-L121】.</p></div><div class="footer"><div class="data-bar"></div></div></div></div></div><div id="right-content" class="leaf" style="--sidebar-width: var(--sidebar-width-right);"><div id="right-sidebar" class="sidebar"><div class="sidebar-handle"></div><div class="sidebar-topbar"><div class="topbar-content"><label class="theme-toggle-container" for="theme-toggle-input" id=""><input class="theme-toggle-input" type="checkbox" id="theme-toggle-input"><div class="toggle-background"></div></label></div><div class="clickable-icon sidebar-collapse-icon"><svg xmlns="http://www.w3.org/2000/svg" width="100%" height="100%" viewBox="0 0 24 24" fill="none" stroke="currentColor" stroke-width="3" stroke-linecap="round" stroke-linejoin="round" class="svg-icon"><path d="M21 3H3C1.89543 3 1 3.89543 1 5V19C1 20.1046 1.89543 21 3 21H21C22.1046 21 23 20.1046 23 19V5C23 3.89543 22.1046 3 21 3Z"></path><path d="M10 4V20"></path><path d="M4 7H7"></path><path d="M4 10H7"></path><path d="M4 13H7"></path></svg></div></div><div class="sidebar-content-wrapper"><div id="right-sidebar-content" class="leaf-content"><div class="graph-view-wrapper"><div class="feature-header"><div class="feature-title">Interactive Graph</div></div><div class="graph-view-placeholder">
		<div class="graph-view-container">
			<div class="graph-icon graph-expand" role="button" aria-label="Expand" data-tooltip-position="top"><svg xmlns="http://www.w3.org/2000/svg" width="24" height="24" viewBox="0 0 24 24" fill="none" stroke="currentColor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round" class="svg-icon"><line x1="7" y1="17" x2="17" y2="7"></line><polyline points="7 7 17 7 17 17"></polyline></svg></div>
			<div class="graph-icon graph-global" role="button" aria-label="Global Graph" data-tooltip-position="top"><svg xmlns="http://www.w3.org/2000/svg" width="24" height="24" viewBox="0 0 24 24" fill="none" stroke="currentColor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round" class="svg-icon lucide-git-fork"><circle cx="12" cy="18" r="3"></circle><circle cx="6" cy="6" r="3"></circle><circle cx="18" cy="6" r="3"></circle><path d="M18 9v2c0 .6-.4 1-1 1H7c-.6 0-1-.4-1-1V9"></path><path d="M12 12v3"></path></svg></div>
			<canvas id="graph-canvas" class="hide" width="512px" height="512px"></canvas>
		</div>
		</div></div><div id="outline" class=" tree-container"><div class="feature-header"><div class="feature-title">Table Of Contents</div><button class="clickable-icon nav-action-button tree-collapse-all" aria-label="Collapse All"><svg xmlns="http://www.w3.org/2000/svg" width="24" height="24" viewBox="0 0 24 24" fill="none" stroke="currentColor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round"></svg></button></div><div class="tree-item" data-depth="1"><a class="tree-item-self is-clickable" href="projeto/llm-alfred/deep-research-report.html#deep-research-report_0" data-path="#deep-research-report_0"><div class="tree-item-inner heading-link" heading-name="deep-research-report">deep-research-report</div></a><div class="tree-item-children"></div></div><div class="tree-item mod-collapsible" data-depth="1"><a class="tree-item-self is-clickable mod-collapsible" href="projeto/llm-alfred/deep-research-report.html#Criação_de_Agente_de_IA_Local_com_Ollama_e_Base_de_Conhecimento_em_Markdown_0" data-path="#Criação_de_Agente_de_IA_Local_com_Ollama_e_Base_de_Conhecimento_em_Markdown_0"><div class="tree-item-icon collapse-icon"><svg xmlns="http://www.w3.org/2000/svg" width="24" height="24" viewBox="0 0 24 24" fill="none" stroke="currentColor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round" class="svg-icon right-triangle"><path d="M3 8L12 17L21 8"></path></svg></div><div class="tree-item-inner heading-link" heading-name="Criação de Agente de IA Local com Ollama e Base de Conhecimento em Markdown">Criação de Agente de IA Local com Ollama e Base de Conhecimento em Markdown</div></a><div class="tree-item-children"><div class="tree-item" data-depth="2"><a class="tree-item-self is-clickable" href="projeto/llm-alfred/deep-research-report.html#Resumo_Executivo_0" data-path="#Resumo_Executivo_0"><div class="tree-item-inner heading-link" heading-name="Resumo Executivo">Resumo Executivo</div></a><div class="tree-item-children"></div></div><div class="tree-item" data-depth="2"><a class="tree-item-self is-clickable" href="projeto/llm-alfred/deep-research-report.html#1._Requisitos_de_Hardware_e_Software_0" data-path="#1._Requisitos_de_Hardware_e_Software_0"><div class="tree-item-inner heading-link" heading-name="1. Requisitos de Hardware e Software">1. Requisitos de Hardware e Software</div></a><div class="tree-item-children"></div></div><div class="tree-item" data-depth="2"><a class="tree-item-self is-clickable" href="projeto/llm-alfred/deep-research-report.html#2._Instalação_e_Configuração_do_Ollama_0" data-path="#2._Instalação_e_Configuração_do_Ollama_0"><div class="tree-item-inner heading-link" heading-name="2. Instalação e Configuração do Ollama">2. Instalação e Configuração do Ollama</div></a><div class="tree-item-children"></div></div><div class="tree-item" data-depth="2"><a class="tree-item-self is-clickable" href="projeto/llm-alfred/deep-research-report.html#3._Modelos_Compatíveis_(Comparativo)_0" data-path="#3._Modelos_Compatíveis_(Comparativo)_0"><div class="tree-item-inner heading-link" heading-name="3. Modelos Compatíveis (Comparativo)">3. Modelos Compatíveis (Comparativo)</div></a><div class="tree-item-children"></div></div><div class="tree-item" data-depth="2"><a class="tree-item-self is-clickable" href="projeto/llm-alfred/deep-research-report.html#4._Treinamento_e_Ajustes_(Fine-Tuning)_0" data-path="#4._Treinamento_e_Ajustes_(Fine-Tuning)_0"><div class="tree-item-inner heading-link" heading-name="4. Treinamento e Ajustes (Fine-Tuning)">4. Treinamento e Ajustes (Fine-Tuning)</div></a><div class="tree-item-children"></div></div><div class="tree-item" data-depth="2"><a class="tree-item-self is-clickable" href="projeto/llm-alfred/deep-research-report.html#5._Pipeline_de_Ingestão_e_Indexação_de_Markdown_0" data-path="#5._Pipeline_de_Ingestão_e_Indexação_de_Markdown_0"><div class="tree-item-inner heading-link" heading-name="5. Pipeline de Ingestão e Indexação de Markdown">5. Pipeline de Ingestão e Indexação de Markdown</div></a><div class="tree-item-children"></div></div><div class="tree-item" data-depth="2"><a class="tree-item-self is-clickable" href="projeto/llm-alfred/deep-research-report.html#6._Mecanismos_de_Busca_e_Recuperação_0" data-path="#6._Mecanismos_de_Busca_e_Recuperação_0"><div class="tree-item-inner heading-link" heading-name="6. Mecanismos de Busca e Recuperação">6. Mecanismos de Busca e Recuperação</div></a><div class="tree-item-children"></div></div><div class="tree-item" data-depth="2"><a class="tree-item-self is-clickable" href="projeto/llm-alfred/deep-research-report.html#7._Arquitetura_do_Agente_Conversacional_0" data-path="#7._Arquitetura_do_Agente_Conversacional_0"><div class="tree-item-inner heading-link" heading-name="7. Arquitetura do Agente Conversacional">7. Arquitetura do Agente Conversacional</div></a><div class="tree-item-children"></div></div><div class="tree-item" data-depth="2"><a class="tree-item-self is-clickable" href="projeto/llm-alfred/deep-research-report.html#8._Exemplos_de_Código_e_Comandos_0" data-path="#8._Exemplos_de_Código_e_Comandos_0"><div class="tree-item-inner heading-link" heading-name="8. Exemplos de Código e Comandos">8. Exemplos de Código e Comandos</div></a><div class="tree-item-children"></div></div><div class="tree-item" data-depth="2"><a class="tree-item-self is-clickable" href="projeto/llm-alfred/deep-research-report.html#9._Formatos_de_Dados_e_Esquemas_0" data-path="#9._Formatos_de_Dados_e_Esquemas_0"><div class="tree-item-inner heading-link" heading-name="9. Formatos de Dados e Esquemas">9. Formatos de Dados e Esquemas</div></a><div class="tree-item-children"></div></div><div class="tree-item" data-depth="2"><a class="tree-item-self is-clickable" href="projeto/llm-alfred/deep-research-report.html#10._Avaliação_e_Métricas_0" data-path="#10._Avaliação_e_Métricas_0"><div class="tree-item-inner heading-link" heading-name="10. Avaliação e Métricas">10. Avaliação e Métricas</div></a><div class="tree-item-children"></div></div><div class="tree-item" data-depth="2"><a class="tree-item-self is-clickable" href="projeto/llm-alfred/deep-research-report.html#11._Boas_Práticas_de_Deploy_e_Manutenção_0" data-path="#11._Boas_Práticas_de_Deploy_e_Manutenção_0"><div class="tree-item-inner heading-link" heading-name="11. Boas Práticas de Deploy e Manutenção">11. Boas Práticas de Deploy e Manutenção</div></a><div class="tree-item-children"></div></div><div class="tree-item" data-depth="2"><a class="tree-item-self is-clickable" href="projeto/llm-alfred/deep-research-report.html#12._Riscos_e_Limitações_0" data-path="#12._Riscos_e_Limitações_0"><div class="tree-item-inner heading-link" heading-name="12. Riscos e Limitações">12. Riscos e Limitações</div></a><div class="tree-item-children"></div></div><div class="tree-item" data-depth="2"><a class="tree-item-self is-clickable" href="projeto/llm-alfred/deep-research-report.html#13._Recursos_e_Leituras_Adicionais_0" data-path="#13._Recursos_e_Leituras_Adicionais_0"><div class="tree-item-inner heading-link" heading-name="13. Recursos e Leituras Adicionais">13. Recursos e Leituras Adicionais</div></a><div class="tree-item-children"></div></div><div class="tree-item" data-depth="2"><a class="tree-item-self is-clickable" href="projeto/llm-alfred/deep-research-report.html#14._Suposições_Não_Especificadas_0" data-path="#14._Suposições_Não_Especificadas_0"><div class="tree-item-inner heading-link" heading-name="14. Suposições Não Especificadas">14. Suposições Não Especificadas</div></a><div class="tree-item-children"></div></div></div></div></div></div></div><script defer="">let rs = document.querySelector("#right-sidebar"); rs.classList.toggle("is-collapsed", window.innerWidth < 768); rs.style.setProperty("--sidebar-width", localStorage.getItem("sidebar-right-width"));</script></div></div></div></div></body></html>